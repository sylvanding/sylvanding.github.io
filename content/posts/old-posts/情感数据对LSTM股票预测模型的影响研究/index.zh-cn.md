+++
title = "æƒ…æ„Ÿæ•°æ®å¯¹LSTMè‚¡ç¥¨é¢„æµ‹æ¨¡å‹çš„å½±å“ç ”ç©¶"
date = 2021-06-28T00:00:00+08:00
draft = false
slug = 'old-4'
+++

# æƒ…æ„Ÿæ•°æ®å¯¹LSTMè‚¡ç¥¨é¢„æµ‹æ¨¡å‹çš„å½±å“ç ”ç©¶

**æ‘˜è¦**ï¼šæ¢ç©¶äº†æƒ…æ„Ÿç»“æ„åŒ–ç‰¹å¾æ•°æ®åœ¨LSTMè‚¡ç¥¨é¢„æµ‹æ¨¡å‹ä¸­çš„å½±å“ã€‚åˆ©ç”¨Pandaså¯¹æ‰€ç»™æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ˆæ•°æ®è½½å…¥ã€æ¸…æ´—ä¸å‡†å¤‡ã€è§„æ•´ã€æ—¶é—´åºåˆ—å¤„ç†ã€æ•°æ®èšåˆç­‰ï¼‰ã€‚<a id="toref1" href="#ref1">[1]</a> å€ŸåŠ©NLTKå’ŒLMé‡‘èè¯åº“ï¼Œå¯¹éç»“æ„åŒ–æ–‡æœ¬ä¿¡æ¯è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œå¹¶å°†æ‰€å¾—ç»“æ„åŒ–æ•°æ®èå…¥çº¯æŠ€æœ¯æŒ‡æ ‡çš„è‚¡ç¥¨æ•°æ®ä¸­ã€‚åˆ†æå„è‚¡ç¥¨æŒ‡æ ‡çš„ç›¸å…³æ€§ï¼Œå®ç°æ•°æ®é™ç»´ã€‚åŸºäºKerasçš„ä»¥MSEä¸ºè¯¯å·®è¯„ä»·æ–¹æ³•çš„LSTMæ¨¡å‹ï¼Œå®ç°å¯¹è‚¡ç¥¨æ”¶ç›˜ä»·Closeçš„é¢„æµ‹ã€‚æœ€ç»ˆå¾—å‡ºå½“è®­ç»ƒæ ·æœ¬å……è¶³æ—¶ï¼Œèå…¥äº†æƒ…æ„Ÿç‰¹å¾æ•°æ®ï¼Œä½¿å¾—é¢„æµ‹ç²¾åº¦é€‚å½“å¢åŠ çš„ç»“è®ºã€‚

> **å®éªŒè¯´æ˜**ï¼š
>
> **è®¾è®¡ä¸€ä¸ªé¢„æµ‹è‚¡ç¥¨ä»·æ ¼çš„æ–¹æ³•ï¼Œå¹¶ç”¨å®ä¾‹è¯æ˜æ­¤æ–¹æ³•çš„æœ‰æ•ˆæ€§**ã€‚
>
> æ‰€ç»™çš„æ•°æ®ï¼Œè¦æ±‚å…¨éƒ¨éƒ½è¦ä½¿ç”¨ï¼Œæ³¨æ„æ•°æ®éœ€æ¸…æ´—ã€ç‰¹å¾ç»¼åˆä½¿ç”¨ï¼Œå¯è‡ªå·±é¢å¤–è¡¥å……èµ„æºæˆ–æ•°æ®ã€‚
>
> **æä¾›çš„æ•°æ®è¯´æ˜**ï¼š
>
> 1. å…¨æ ‡é¢˜  
>
>    a)    è¿™æ˜¯è‚¡ç¥¨å¹³å°ä¸Šå‘å¸ƒçš„å¯¹å„å…¬å¸çš„åˆ†ææ–‡ç« 
>
>    b)   æ ‡é¢˜ï¼šæ–‡ç« çš„æ ‡é¢˜
>
>    c)    å­—æ®µ1_é“¾æ¥_é“¾æ¥ï¼šåŸæ–‡ç« æ‰€åœ¨çš„URL
>
>    d)   ABOUTï¼šæ–‡ç« é’ˆå¯¹çš„å…¬å¸ï¼Œéƒ½ä¸ºç¼©å†™å½¢å¼ï¼Œå¤šä¸ªå…¬å¸ä»¥é€—å·éš”å¼€
>
>    e)    TIMEï¼šæ–‡ç« å‘å¸ƒçš„æ—¶é—´
>
>    f)    AUTHORï¼šä½œè€…
>
>    g)    COMMENTSï¼šé‡‡é›†æ—¶ï¼Œæ–‡ç« çš„è¢«è¯„è®ºæ¬¡æ•°
>
> 2. æ‘˜è¦
>
>    a)    è¿™æ˜¯è‚¡ç¥¨å¹³å°ä¸Šå‘å¸ƒçš„å¯¹å„å…¬å¸çš„åˆ†ææ–‡ç« çš„æ‘˜è¦éƒ¨åˆ†ï¼Œå’Œâ€œå…¨æ ‡é¢˜â€ä¸­çš„å†…å®¹å¯¹åº”
>
>    b)   æ ‡é¢˜ï¼šæ–‡ç« çš„æ ‡é¢˜
>
>    c)    å­—æ®µ2ï¼šæ–‡ç« å‘å¸ƒçš„æ—¶é—´
>
>    d)   å­—æ®µ5ï¼šæ–‡ç« é’ˆå¯¹çš„å…¬å¸åŠæåŠçš„å…¬å¸ï¼›
>
>    â€‹          i.      Aboutä¸ºé’ˆå¯¹å…¬å¸ï¼Œéƒ½æå–ç¼©å†™çš„å¤§å†™æ¨¡å‹ï¼Œå¤šä¸ªå…¬å¸ä»¥é€—å·éš”å¼€
>
>    â€‹         ii.      includeä¸ºæåŠçš„å…¶å®ƒå…¬å¸ï¼Œéƒ½æå–ç¼©å†™çš„å¤§å†™æ¨¡å‹ï¼Œå¤šä¸ªå…¬å¸ä»¥é€—å·éš”å¼€
>
>    e)    å­—æ®µ1ï¼šæ‘˜è¦çš„å…¨æ–‡å­—å†…å®¹
>
> 3. å›å¸–
>
>    a)    è¿™æ˜¯ç½‘å‹åœ¨å„æ–‡ç« ä¸‹çš„å›å¤å†…å®¹ 
>
>    b)   Titleï¼šå„æ–‡ç« çš„æ ‡é¢˜ï¼›ç©ºæ ‡é¢˜çš„ï¼Œç”¨æœ€é è¿‘çš„æœ‰å†…å®¹çš„ä¸‹æ–¹æ ‡é¢˜
>
>    c)    Contentï¼šå›å¤çš„å…¨æ–‡å­—å†…å®¹
>
> 4. è®ºå›
>
>    a)    è¿™æ˜¯ç½‘å‹åœ¨å„å…¬å¸çš„è®ºå›é¡µé¢ä¸‹ï¼Œå¯¹ä¹‹è¿›è¡Œè¯„è®ºçš„å‘å¸–å†…å®¹ 
>
>    b)   å­—æ®µ1ï¼šä½œè€…
>
>    c)    å­—æ®µ2ï¼šå‘å¸–æ—¥æœŸ
>
>    d)   å­—æ®µ3ï¼šå¸–å­å†…å®¹
>
>    e)    å­—æ®µ4_é“¾æ¥ï¼šå…·ä½“çš„å„å…¬å¸çš„é¡µé¢URL
>
> 5. è‚¡ç¥¨ä»·æ ¼
>
>    a)    ä¸ºå„å…¬å¸å·¥ä½œæ—¥è‚¡ç¥¨çš„ä»·æ ¼
>
>    b)   PERMNOï¼šå…¬å¸ç¼–å·
>
>    c)    Dateï¼šæ—¥æœŸ
>
>    d)   TICKERï¼šå…¬å¸ç®€å†™
>
>    e)    COMNAMï¼šå…¬å¸å…¨å†™
>
>    f)    BIDLOï¼šæœ€ä½ä»·
>
>    g)    ASKHIï¼šæœ€é«˜ä»·
>
>    h)   PRCï¼š æ”¶ç›˜ä»·
>
>    i)    VOLï¼šæˆäº¤é‡
>
>    j)    OPENPRCï¼š å¼€ç›˜ä»·



[TOC]



**æ ¸å¿ƒæ€æƒ³**ï¼šä½¿ç”¨LSTMæ¨¡å‹è§£å†³è‚¡ç¥¨æ•°æ®çš„æ—¶é—´åºåˆ—é¢„æµ‹é—®é¢˜å’Œä½¿ç”¨NLTKåº“å¯¹æ–‡æœ¬æƒ…æ„Ÿè¿›è¡Œåˆ†æã€‚

**æ ¹æœ¬è§‚ç‚¹**ï¼šå†å²ä¼šä¸æ–­é‡æ¼”ã€‚æœ¬æ¬¡ä½œä¸šå‡åŸºäºå¦‚ä¸‹å‡è®¾ï¼Œè‚¡ç¥¨è§„å¾‹å¹¶ä¸æ˜¯å®Œå…¨éšæœºçš„ï¼Œè€Œæ˜¯å—äººç±»å¿ƒç†å­¦ä¸­æŸäº›è§„å¾‹çš„åˆ¶çº¦ï¼Œåœ¨é¢å¯¹ç›¸ä¼¼çš„æƒ…å¢ƒæ—¶ï¼Œä¼šæ ¹æ®ä»¥å¾€çš„ç»éªŒå’Œè§„å¾‹ä½œå‡ºç›¸ä¼¼çš„ååº”ã€‚å› æ­¤ï¼Œå¯ä»¥æ ¹æ®å†å²èµ„æ–™çš„æ•°æ®æ¥é¢„æµ‹æœªæ¥è‚¡ç¥¨çš„æ³¢åŠ¨è¶‹åŠ¿ã€‚åœ¨è‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡ä¸­ï¼Œæ”¶ç›˜ä»·æ˜¯ä¸€å¤©ç»“æŸæ—¶çš„ä»·æ ¼ï¼Œåˆæ˜¯ç¬¬äºŒå¤©çš„å¼€ç›˜ä»·ï¼Œè”ç³»å‰åä¸¤å¤©ï¼Œå› æ­¤æœ€ä¸ºé‡è¦ã€‚<a id="toref2" href="#ref2">[2]</a>

**å½±å“å› ç´ **ï¼šå½±å“è‚¡ç¥¨ä»·æ ¼çš„å› ç´ é™¤äº†åŸºæœ¬çš„è‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡å¤–ï¼Œè‚¡ç¥¨ä»·æ ¼è¿˜å’Œè‚¡æ°‘çš„æƒ…ç»ªå’Œç›¸å…³è‚¡ç¥¨åˆ†ææ–‡ç« çš„æƒ…æ„Ÿå¯†åˆ‡ç›¸å…³ã€‚

**åˆ†ææ–¹æ³•**ï¼šå°†è‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡å’Œè‚¡æ°‘å¤§ä¼—çš„æƒ…æ„Ÿè¯„ä»·ç›¸ç»“åˆ<a id="toref3" href="#ref3">[3]</a>ï¼Œé€‰æ‹©AAPLä¸ªè‚¡ï¼Œå¯¹è‚¡ç¥¨ä»·æ ¼ï¼Œå³`æ”¶ç›˜ä»·`è¿›è¡Œé¢„æµ‹ã€‚åˆ†åˆ«å¯¹åªå«æœ‰æŠ€æœ¯æŒ‡æ ‡å’Œå«æœ‰æŠ€æœ¯æŒ‡æ ‡å’Œæƒ…æ„Ÿè¯„ä»·çš„æ ·æœ¬è¿›è¡ŒLSTMå»ºæ¨¡ï¼Œä½¿ç”¨`MSE`ï¼ˆå‡æ–¹è¯¯å·®ï¼‰ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œå¯¹äºŒè€…é¢„æµ‹ç»“æœè¿›è¡Œè¯„ä»·ã€‚

## 1 LSTM

### 1.1 LSTMæ˜¯ä»€ä¹ˆï¼Ÿ

`LSTM Networks`ï¼ˆLong Short-Term Memoryï¼‰*\- Hochreiter 1997*ï¼Œé•¿çŸ­æœŸè®°å¿†ç¥ç»ç½‘ç»œï¼Œæ˜¯ä¸€ç§ç‰¹æ®Šçš„RNNï¼Œèƒ½å¤Ÿå­¦ä¹ é•¿çš„ä¾èµ–å…³ç³»ï¼Œè®°ä½è¾ƒé•¿çš„å†å²ä¿¡æ¯ã€‚

### 1.2 ä¸ºä»€ä¹ˆå†³å®šä½¿ç”¨LSTMï¼Ÿ

Deep Neural Networks (DNN)ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œï¼Œæœ‰è‹¥å¹²è¾“å…¥å’Œä¸€ä¸ªè¾“å‡ºï¼Œåœ¨è¾“å‡ºå’Œè¾“å…¥é—´å­¦ä¹ å¾—åˆ°ä¸€ä¸ªçº¿æ€§å…³ç³»ï¼Œæ¥ç€é€šè¿‡ä¸€ä¸ªç¥ç»å…ƒæ¿€æ´»å‡½æ•°å¾—åˆ°ç»“æœ1æˆ–-1. ä½†DNNä¸èƒ½è¾ƒå¥½åœ°å¤„ç†æ—¶é—´åºåˆ—æ•°æ®ã€‚Recurrent Neural Networks (RNN)ï¼Œå¾ªç¯ç¥ç»ç½‘ç»œï¼Œå¯ä»¥æ›´å¥½åœ°å¤„ç†åºåˆ—ä¿¡æ¯ï¼Œä½†å…¶ç¼ºç‚¹æ˜¯ä¸èƒ½è®°å¿†è¾ƒé•¿æ—¶æœŸçš„æ—¶é—´åºåˆ—ï¼Œè€Œä¸” Standard RNN Shortcomings éš¾ä»¥è®­ç»ƒï¼Œç»™å®šåˆå€¼æ¡ä»¶ä¸‹ï¼Œæ”¶æ•›éš¾åº¦å¤§ã€‚

LSTMè§£å†³äº†RNNçš„ç¼ºé™·ã€‚LSTMç›¸è¾ƒäºRNNæ¨¡å‹å¢åŠ äº†Forget Gate Layerï¼ˆé—å¿˜é—¨ï¼‰ï¼Œå¯ä»¥å¯¹ä¸Šä¸€ä¸ªèŠ‚ç‚¹ä¼ è¿›çš„è¾“å…¥è¿›è¡Œé€‰æ‹©æ€§å¿˜è®°ã€‚æ¥ç€ï¼Œé€‰æ‹©éœ€è¦è®°å¿†çš„é‡è¦è¾“å…¥ä¿¡æ¯ã€‚ä¹Ÿå°±æ˜¯â€œå¿˜è®°ä¸é‡è¦çš„ï¼Œè®°ä½é‡è¦çš„â€ã€‚è¿™æ ·ï¼Œå°±**è§£å†³äº†RNNåœ¨é•¿åºåˆ—è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œåœ¨é•¿åºåˆ—è®­ç»ƒä¸­æœ‰æ›´ä½³çš„è¡¨ç°**ã€‚å› æ­¤ï¼Œæˆ‘é€‰ç”¨LSTMä½œä¸ºè‚¡ç¥¨æ—¶é—´åºåˆ—æ•°æ®çš„è®­ç»ƒæ¨¡å‹ã€‚

## 2 æ·±åº¦å­¦ä¹ åè¯æ¦‚å¿µè§£é‡Š

| Wrods     | Definitions                                                  |
| --------- | ------------------------------------------------------------ |
| Epoch     | ä½¿ç”¨è®­ç»ƒé›†çš„å…¨éƒ¨æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œä¸€æ¬¡å®Œæ•´çš„è®­ç»ƒï¼Œè¢«ç§°ä¹‹ä¸ºâ€œ**ä¸€ä»£è®­ç»ƒ**â€ã€‚åŒ…æ‹¬ä¸€æ¬¡æ­£å‘ä¼ æ’­å’Œä¸€æ¬¡åå‘ä¼ æ’­ |
| Batch     | ä½¿ç”¨è®­ç»ƒé›†ä¸­çš„ä¸€å°éƒ¨åˆ†æ ·æœ¬å¯¹æ¨¡å‹æƒé‡è¿›è¡Œä¸€æ¬¡åå‘ä¼ æ’­çš„å‚æ•°æ›´æ–°ï¼Œè¿™ä¸€å°éƒ¨åˆ†æ ·æœ¬è¢«ç§°ä¸ºâ€œ**ä¸€æ‰¹æ•°æ®**â€ |
| Iteration | ä½¿ç”¨ä¸€ä¸ª**Batch**æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œä¸€æ¬¡å‚æ•°æ›´æ–°çš„è¿‡ç¨‹ï¼Œè¢«ç§°ä¹‹ä¸ºâ€œ**ä¸€æ¬¡è¿­ä»£** |

[Source1] https://www.jianshu.com/p/22c50ded4cf7?from=groupmessage

### 2.1 ä¸ºä»€ä¹ˆè¦ä½¿ç”¨å¤šäºä¸€ä¸ªepochï¼Ÿ

åªä¼ é€’ä¸€æ¬¡å®Œæ•´æ•°æ®é›†æ˜¯ä¸å¤Ÿçš„ï¼Œéœ€è¦åœ¨ç¥ç»ç½‘ç»œä¸­ä¼ é€’å¤šæ¬¡ã€‚éšç€`epoch`æ•°é‡çš„å¢åŠ ï¼Œç¥ç»ç½‘ç»œä¸­çš„æƒé‡æ›´æ–°æ¬¡æ•°ä¹Ÿåœ¨å¢åŠ ï¼Œè¿™å°±å¯¼è‡´äº†æ‹Ÿåˆæ›²çº¿ä»æ¬ æ‹Ÿåˆå˜ä¸ºè¿‡æ‹Ÿåˆã€‚

æ¯æ¬¡epochä¹‹åï¼Œéœ€è¦å¯¹æ€»æ ·æœ¬shuffleï¼Œå†è¿›å…¥ä¸‹ä¸€è½®è®­ç»ƒã€‚ï¼ˆæœ¬æ¬¡å®éªŒä¸ç”¨shuffleï¼‰

å¯¹ä¸åŒæ•°æ®é›†ï¼Œepochä¸ªæ•°ä¸åŒã€‚

### 2.2 Batch å’Œ Batch_Size

ç›®å‰ç»å¤§éƒ¨åˆ†æ·±åº¦å­¦ä¹ æ¡†æ¶ä½¿ç”¨`Mini-batch Gradient Decent` å°æ‰¹æ¢¯åº¦ä¸‹é™ï¼ŒæŠŠæ•°æ®åˆ†ä¸ºè‹¥å¹²æ‰¹ï¼ˆ`Batch`ï¼‰ï¼Œæ¯æ‰¹æœ‰`Batch_Size`ä¸ªæ•°æ®ï¼ŒæŒ‰æ‰¹æ›´æ–°æƒé‡ï¼Œä¸€ä¸ªBatchä¸­çš„ä¸€ç»„æ•°æ®å…±åŒå†³å®šæœ¬æ¬¡æ¢¯åº¦çš„ä¸‹é™æ–¹å‘ã€‚
$$
Number of Batches = \frac{Training Set Size}{Batch Size}
$$

> å°æ‰¹æ¢¯åº¦ä¸‹é™å…‹æœäº†åœ¨æ•°æ®é‡è¾ƒå¤§çš„æƒ…å†µä¸‹æ—¶ï¼ŒBatch Gradient Decent çš„è®¡ç®—å¼€é”€å¤§ã€é€Ÿåº¦æ…¢ å’Œ Stochastic Gradient Decent çš„éšæœºæ€§ã€æ”¶æ•›æ•ˆæœä¸ä½³çš„ç¼ºç‚¹ã€‚

[Source2] https://blog.csdn.net/dancing_power/article/details/97015723 

### 2.3 Iterations

ä¸€æ¬¡iterationè¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ã€‚å‰å‘ä¼ æ’­ï¼ŒåŸºäºå±æ€§Xï¼Œå¾—åˆ°é¢„æµ‹ç»“æœyã€‚åå‘ä¼ æ’­æ ¹æ®ç»™å®šçš„æŸå¤±å‡½æ•°ï¼Œæ±‚è§£å‚æ•°ï¼ˆæƒé‡ï¼‰ã€‚
$$
Numbers of Iterations = Number of Batched
$$

### 2.4 ä¸ºä»€ä¹ˆä¸è¦shuffleï¼Ÿ

é¿å…æ•°æ®æŠ•å…¥çš„é¡ºåºå¯¹ç½‘ç»œè®­ç»ƒé€ æˆå½±å“ï¼Œå¢åŠ è®­ç»ƒçš„éšæœºæ€§ï¼Œæé«˜ç½‘ç»œçš„æ³›åŒ–æ€§èƒ½ã€‚

**ä½†æ˜¯é’ˆå¯¹æœ¬æ¬¡è‚¡ç¥¨ä»·æ ¼çš„é¢„æµ‹ï¼Œä½¿ç”¨LSTMæ¨¡å‹ï¼Œè€ƒè™‘æ—¶é—´å› ç´ ï¼Œå› æ­¤ï¼Œéœ€è¦è®¾ç½®`shuffle=False`ï¼ŒæŒ‰æ—¶åºé¡ºåºä¾æ¬¡ä½¿ç”¨Batchæ›´æ–°å‚æ•°ã€‚**

## 3 å®éªŒè¿‡ç¨‹

ä»¥ä¸‹å®éªŒå‡åŸºäºå¯¹`Apple, Inc.`ï¼ˆAAPLï¼‰è‹¹æœå…¬å¸çš„è‚¡ç¥¨è¿›è¡Œé¢„æµ‹åˆ†æã€‚

`CORPORATIONABBR = 'AAPL'`

### 3.1 åº“å¯¼å…¥

```python
# æ•°æ®åˆ†æçš„æ ¸å¿ƒåº“
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
# æ—¶é—´åºåˆ—å¤„ç†
from datetime import datetime
from dateutil.parser import parse as dt_parse
# æ­£åˆ™åº“
import re
# osåº“
from os import listdir
# NLTKè‡ªç„¶è¯­è¨€å¤„ç†åº“
import nltk
from nltk.corpus import stopwords
# seabornæˆå¯¹å›¾çŸ©é˜µç”Ÿæˆ
from seaborn import pairplot
# sklearnåº“çš„å½’ä¸€åŒ–ã€è®­ç»ƒé›†æµ‹è¯•é›†åˆ’åˆ†
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
# Keras LSTM
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
# sklearn MSE
from sklearn.metrics import mean_squared_error
```

### 3.2 pandasæ ¸å¿ƒè®¾ç½®

```python
# è®¾ç½®pandasçš„æœ€å¤§æ˜¾ç¤ºè¡Œæ•°ã€åˆ—æ•°å’Œè¾“å‡ºå®½åº¦
pd.set_option('display.max_rows', 6)
pd.set_option('display.max_columns', 999)
pd.set_option('display.max_colwidth', 50)
```

### 3.3 æ•°æ®è½½å…¥ã€æ•°æ®æ¸…æ´—ä¸å‡†å¤‡ã€æ•°æ®è§„æ•´ã€æ—¶é—´åºåˆ—å¤„ç†

#### 3.3.1 è‚¡ç¥¨ä»·æ ¼.csv

```python
sharePrices = pd.read_csv('è‚¡ç¥¨ä»·æ ¼.csv')
sharePrices
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PERMNO</th>
      <th>date</th>
      <th>TICKER</th>
      <th>COMNAM</th>
      <th>BIDLO</th>
      <th>ASKHI</th>
      <th>PRC</th>
      <th>VOL</th>
      <th>OPENPRC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10026</td>
      <td>20180702</td>
      <td>JJSF</td>
      <td>J &amp; J SNACK FOODS CORP</td>
      <td>150.70000</td>
      <td>153.27499</td>
      <td>152.92000</td>
      <td>100388.0</td>
      <td>152.17999</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10026</td>
      <td>20180703</td>
      <td>JJSF</td>
      <td>J &amp; J SNACK FOODS CORP</td>
      <td>151.35001</td>
      <td>153.73000</td>
      <td>153.32001</td>
      <td>55547.0</td>
      <td>153.67000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10026</td>
      <td>20180705</td>
      <td>JJSF</td>
      <td>J &amp; J SNACK FOODS CORP</td>
      <td>152.46001</td>
      <td>156.00000</td>
      <td>155.81000</td>
      <td>199370.0</td>
      <td>153.95000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>941515</th>
      <td>93436</td>
      <td>20181227</td>
      <td>TSLA</td>
      <td>TESLA INC</td>
      <td>301.50000</td>
      <td>322.17169</td>
      <td>316.13000</td>
      <td>8575133.0</td>
      <td>319.84000</td>
    </tr>
    <tr>
      <th>941516</th>
      <td>93436</td>
      <td>20181228</td>
      <td>TSLA</td>
      <td>TESLA INC</td>
      <td>318.41000</td>
      <td>336.23999</td>
      <td>333.87000</td>
      <td>9938992.0</td>
      <td>323.10001</td>
    </tr>
    <tr>
      <th>941517</th>
      <td>93436</td>
      <td>20181231</td>
      <td>TSLA</td>
      <td>TESLA INC</td>
      <td>325.26001</td>
      <td>339.20999</td>
      <td>332.79999</td>
      <td>6302338.0</td>
      <td>337.79001</td>
    </tr>
  </tbody>
</table>
<p>941518 rows Ã— 9 columns</p>
</div>

**ç´¢å¼•è¿‡æ»¤**ï¼šç´¢å¼•è¿‡æ»¤å‡ºTICKERï¼ˆå…¬å¸ç®€å†™ï¼‰ä¸ºAAPLçš„æ•°æ®è¡Œã€‚

```python
sharePricesAAPL = sharePrices[sharePrices['TICKER']==CORPORATIONABBR]
```

**DataFrameé™ç»´**ï¼šä¸éœ€è¦PERMNOï¼ˆå…¬å¸ç¼–å·ï¼‰ã€COMNAMï¼ˆå…¬å¸å…¨å†™ï¼‰ã€TICKERï¼ˆå…¬å¸ç®€å†™ï¼‰è¿™ä¸‰åˆ—æ•°æ®ï¼Œåˆ é™¤åˆ—ã€‚

```python
sharePricesAAPL.drop(['PERMNO', 'COMNAM', 'TICKER'], axis=1, inplace=True)
```

**ç´¢å¼•æ•°æ®ç±»å‹æ£€æµ‹**ï¼šç¡®ä¿ç›¸åº”ç´¢å¼•çš„æ•°æ®ç±»å‹ä¸ºfloatã€‚

```python
sharePricesAAPL.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 126 entries, 163028 to 163153
    Data columns (total 6 columns):
     #   Column   Non-Null Count  Dtype  
    ---  ------   --------------  -----  
     0   date     126 non-null    int64  
     1   BIDLO    126 non-null    float64
     2   ASKHI    126 non-null    float64
     3   PRC      126 non-null    float64
     4   VOL      126 non-null    float64
     5   OPENPRC  126 non-null    float64
    dtypes: float64(5), int64(1)
    memory usage: 6.9 KB

**ç´¢å¼•æ£€æŸ¥**ï¼šæ£€æŸ¥dateç´¢å¼•æ˜¯å¦å­˜åœ¨é‡å¤ã€‚

```python
sharePricesAAPL['date'].is_unique
```

    True

**æ—¶é—´åºåˆ—**ï¼šå°†dateï¼ˆæ—¥æœŸï¼‰è½¬åŒ–ä¸ºæ—¶é—´åºåˆ—ç´¢å¼•ï¼Œå¹¶æŒ‰æ­¤æ—¶é—´åºåˆ—ä»¥å‡åºæ’åºã€‚

```python
# dateåˆ—è½¬åŒ–ä¸ºdatetimeç±»
sharePricesAAPL['date'] = sharePricesAAPL['date'].apply(lambda dt: datetime.strptime(str(dt), '%Y%m%d'))
# è®¾dateåˆ—ä¸ºç´¢å¼•
sharePricesAAPL.set_index('date', inplace=True)
# æŒ‰dateå‡åºæ’åˆ—
sharePricesAAPL.sort_values(by='date', inplace=True, ascending=True)
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BIDLO</th>
      <th>ASKHI</th>
      <th>PRC</th>
      <th>VOL</th>
      <th>OPENPRC</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-07-02</th>
      <td>183.42000</td>
      <td>187.30</td>
      <td>187.17999</td>
      <td>17612113.0</td>
      <td>183.82001</td>
    </tr>
    <tr>
      <th>2018-07-03</th>
      <td>183.53999</td>
      <td>187.95</td>
      <td>183.92000</td>
      <td>13909764.0</td>
      <td>187.78999</td>
    </tr>
    <tr>
      <th>2018-07-05</th>
      <td>184.28000</td>
      <td>186.41</td>
      <td>185.39999</td>
      <td>16592763.0</td>
      <td>185.25999</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-12-27</th>
      <td>150.07001</td>
      <td>156.77</td>
      <td>156.14999</td>
      <td>53117005.0</td>
      <td>155.84000</td>
    </tr>
    <tr>
      <th>2018-12-28</th>
      <td>154.55000</td>
      <td>158.52</td>
      <td>156.23000</td>
      <td>42291347.0</td>
      <td>157.50000</td>
    </tr>
    <tr>
      <th>2018-12-31</th>
      <td>156.48000</td>
      <td>159.36</td>
      <td>157.74001</td>
      <td>35003466.0</td>
      <td>158.53000</td>
    </tr>
  </tbody>
</table>
<p>126 rows Ã— 5 columns</p>
</div>

**ç¼ºå¤±å€¼å¤„ç†**ï¼šæ£€æŸ¥AAPLè‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡æ•°æ®æ¯åˆ—ç¼ºå¤±æ¯”ï¼Œå‘ç°æ— ç¼ºå¤±ã€‚è‹¥æœ‰ï¼Œåˆ™å¯å¯¹BIDLOï¼ˆæœ€ä½ä»·ï¼‰ã€ASKHIï¼ˆæœ€é«˜ä»·ï¼‰ã€PRCæ”¶ç›˜ä»·ã€VOLï¼ˆæˆäº¤é‡ï¼‰æœ‰ç¼ºå¤±çš„æ•°æ®è¡Œç›´æ¥åˆ é™¤ã€‚å¯¹OPENPRCï¼ˆå¼€ç›˜ä»·ï¼‰æœ‰ç¼ºå¤±çš„ä½¿ç”¨*æ‹‰æ ¼æœ—æ—¥æ’å€¼æ³•*è¿›è¡Œå¡«å……ã€‚

> å…¶å®ä¹‹åå¯¹`è‚¡ç¥¨ä»·æ ¼.csv`åˆ†æå¯çŸ¥ï¼Œç¼ºå¤±é¡¹çš„åˆ†å¸ƒéƒ½åœ¨åŒä¸€è¡Œï¼Œæ•…åªè¦ä½¿ç”¨`df.dropna()`åˆ é™¤å­˜åœ¨ä»»æ„æ•°ç›®ç¼ºå¤±é¡¹çš„è¡Œå³å¯ã€‚

```python
sharePricesAAPL.isnull().mean()
```

    BIDLO      0.0
    ASKHI      0.0
    PRC        0.0
    VOL        0.0
    OPENPRC    0.0
    dtype: float64

**é‡å»ºç´¢å¼•**ï¼šé‡å‘½åç´¢å¼•ï¼Œæ–¹ä¾¿åæœŸä½¿ç”¨ï¼Œæ˜ å°„ä¸ºBIDLO-lowã€ASKHI-highã€PRC-closeã€VOL-volã€OPENPRC-openã€‚æ”¹å˜ç´¢å¼•é¡ºåºä¸ºopenã€highã€lowã€volã€closeã€‚

```python
# rename
AAPL_newIndex = {'BIDLO': 'low',
                 'ASKHI': 'high',
                 'PRC': 'close',
                 'VOL': 'vol',
                 'OPENPRC': 'open'}
sharePricesAAPL.rename(columns=AAPL_newIndex, inplace=True)
# reindex
AAPL_newColOrder = ['open', 'high', 'low', 'vol', 'close']
sharePricesAAPL = sharePricesAAPL.reindex(columns=AAPL_newColOrder)
```

**æ£€æµ‹è¿‡æ»¤å¼‚å¸¸å€¼**ï¼šæ— å¼‚å¸¸ã€‚

```python
sharePricesAAPL.describe()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>vol</th>
      <th>close</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>126.000000</td>
      <td>126.000000</td>
      <td>126.000000</td>
      <td>1.260000e+02</td>
      <td>126.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>201.247420</td>
      <td>203.380885</td>
      <td>198.893344</td>
      <td>3.510172e+07</td>
      <td>201.106033</td>
    </tr>
    <tr>
      <th>std</th>
      <td>21.368524</td>
      <td>21.499932</td>
      <td>21.596966</td>
      <td>1.577876e+07</td>
      <td>21.663971</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>207.320000</td>
      <td>209.375000</td>
      <td>205.785150</td>
      <td>3.234006e+07</td>
      <td>207.760005</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>219.155000</td>
      <td>222.172503</td>
      <td>216.798175</td>
      <td>4.188390e+07</td>
      <td>219.602500</td>
    </tr>
    <tr>
      <th>max</th>
      <td>230.780000</td>
      <td>233.470000</td>
      <td>229.780000</td>
      <td>9.624355e+07</td>
      <td>232.070010</td>
    </tr>
  </tbody>
</table>
<p>8 rows Ã— 5 columns</p>
</div>

**æ•°æ®å­˜å‚¨**ï¼šå­˜å‚¨å¤„ç†å¥½çš„æ•°æ®ä¸º`AAPLè‚¡ç¥¨ä»·æ ¼.csv`ï¼Œå­˜è‡³`è¡¥å……æ•°æ®1925102007`æ–‡ä»¶å¤¹ã€‚æ–¹ä¾¿åç»­è¯»å–ä½¿ç”¨ã€‚

```python
sharePricesAAPL.to_csv('è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼.csv')
```

#### 3.3.2 è®ºå›.csv

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>å­—æ®µ1</th>
      <th>å­—æ®µ2</th>
      <th>å­—æ®µ3</th>
      <th>å­—æ®µ4_é“¾æ¥</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ComputerBlue</td>
      <td>31-Dec-18</td>
      <td>Let's create a small spec POS portfolio $COTY ...</td>
      <td>https://seekingalpha.com/symbol/COTY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Darren McCammon</td>
      <td>31-Dec-18</td>
      <td>$RICK "Now that we've reported results, we'll ...</td>
      <td>https://seekingalpha.com/symbol/RICK</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jonathan Cooper</td>
      <td>31-Dec-18</td>
      <td>Do any $APHA shareholders support the $GGB tak...</td>
      <td>https://seekingalpha.com/symbol/APHA</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>25114</th>
      <td>Power Hedge</td>
      <td>1-Jan-18</td>
      <td>USD Expected to Collapse in 2018 https://goo.g...</td>
      <td>https://goo.gl/RG1CDd</td>
    </tr>
    <tr>
      <th>25115</th>
      <td>Norman Tweed</td>
      <td>1-Jan-18</td>
      <td>Happy New Year everyone! I'm adding to $MORL @...</td>
      <td>https://seekingalpha.com/symbol/MORL</td>
    </tr>
    <tr>
      <th>25116</th>
      <td>User 40986305</td>
      <td>1-Jan-18</td>
      <td>Jamie Diamond says Trump is most pro business ...</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>25117 rows Ã— 4 columns</p>
</div>

**ç¼ºå¤±å€¼å¤„ç†**ï¼šåˆ é™¤å­—æ®µ4ï¼ˆå„å…¬å¸é¡µé¢çš„URLï¼‰ç¼ºå¤±çš„æ•°æ®è¡Œã€‚

```python
forum = pd.read_csv('è®ºå›.csv')
forum.dropna(inplace=True)
```

**å­—ç¬¦ä¸²æ“ä½œå’Œæ­£åˆ™**ï¼šè§‚å¯Ÿå­—æ®µ4ï¼ˆURLï¼‰ï¼Œ`seekingalpha.com/symbol/`ç½‘å€åçš„å†…å®¹ä¸ºå…¬å¸ç®€ç§°ï¼Œä½¿ç”¨pandaså­—ç¬¦ä¸²æ“ä½œå’Œæ­£åˆ™å¯¹å…¬å¸ç®€ç§°è¿›è¡Œæå–ï¼Œæå–å¤±è´¥åˆ™åˆ é™¤è¯¥æ•°æ®è¡Œã€‚å°†å­—æ®µ4çš„æ•°æ®å†…å®¹æ›¿æ¢ä¸ºå…¬å¸ç®€ç§°ã€‚

```python
forum_regExp = re.compile(r'seekingalpha\.com/symbol/([A-Z]+)')
def forumAbbr(link):
    # æˆåŠŸæŸ¥æ‰¾å…¬å¸ç®€ç§°åˆ™è¿”å›ç®€ç§°ï¼Œå¦åˆ™ä»¥ç¼ºå¤±å€¼å¡«è¡¥
    res = forum_regExp.search(link)
    return np.NAN if res is None else res.group(1)
forum['å­—æ®µ4_é“¾æ¥'] = forum['å­—æ®µ4_é“¾æ¥'].apply(forumAbbr)
```

**ç´¢å¼•è¿‡æ»¤**ï¼šæå–æ‰€æœ‰å…¬å¸ç®€ç§°ä¸ºAAPLçš„è¯„è®ºã€‚

**é™ç»´å¤„ç†**ï¼šå­—æ®µ1ï¼ˆä½œè€…åç§°ï¼‰æ— ç”¨ï¼Œå¯ä»¥åˆ é™¤ã€‚

**ç´¢å¼•é‡æ„**ï¼šé‡å‘½åç´¢å¼•ï¼Œå­—æ®µ3ï¼ˆå¸–å­å†…å®¹ï¼‰-remarkã€‚

**æ—¶é—´åºåˆ—**ï¼šå°†å­—æ®µ2è½¬åŒ–ä¸ºæ—¶é—´åºåˆ—ç´¢å¼•ï¼Œå‘½åä¸ºdateï¼Œå¹¶æŒ‰æ­¤ç´¢å¼•å‡åºæ’åˆ—ã€‚

```python
# ç´¢å¼•è¿‡æ»¤
forum = forum[forum['å­—æ®µ4_é“¾æ¥']==CORPORATIONABBR]
# é™ç»´å¤„ç†
forum.drop(['å­—æ®µ1', 'å­—æ®µ4_é“¾æ¥'], axis=1, inplace=True)
# ç´¢å¼•é‡æ„
AAPL_newIndex_forum = {'å­—æ®µ2': 'date', 'å­—æ®µ3': 'remark'}
forum.rename(columns=AAPL_newIndex_forum, inplace=True)
# æ—¶é—´åºåˆ—
forum['date'] = forum['date'].apply(lambda dt: datetime.strptime(str(dt), '%d-%b-%y'))
```

**æ­£åˆ™è¿‡æ»¤è¯„è®ºç½‘å€**ï¼šè§‚å¯Ÿè¯„è®ºä¸éš¾å‘ç°ï¼Œéƒ¨åˆ†è¯„è®ºå†…æœ‰ç½‘å€ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤ä¹‹ï¼Œé˜²æ­¢å¯¹åç»­æƒ…æ„Ÿåˆ†æäº§ç”Ÿå½±å“ã€‚

```python
forum_regExp_linkFilter = re.compile(r'(http|https):\/\/[\w\-_]+(\.[\w\-_]+)+([\w\-\.,@?^=%&:/~\+#]*[\w\-\@?^=%&/~\+#])?')
forum['remark'] = forum['remark'].apply(lambda x: forum_regExp_linkFilter.sub('', x))
forum
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>remark</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>204</th>
      <td>2018-12-26</td>
      <td>Many Chinese companies are encouraging their e...</td>
    </tr>
    <tr>
      <th>418</th>
      <td>2018-12-21</td>
      <td>This Week in Germany ğŸ‡©ğŸ‡ª | Apple Smashed ğŸ“± $AAP...</td>
    </tr>
    <tr>
      <th>471</th>
      <td>2018-12-21</td>
      <td>$AAPL gets hit with another partial ban in Ger...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>24702</th>
      <td>2018-01-05</td>
      <td>$AAPL. Claims by GHH is 200 billion repatriati...</td>
    </tr>
    <tr>
      <th>24902</th>
      <td>2018-01-03</td>
      <td>$AAPL Barclays says battery replacement could ...</td>
    </tr>
    <tr>
      <th>25083</th>
      <td>2018-01-02</td>
      <td>2018 will be the year for $AAPL to hit the 1 t...</td>
    </tr>
  </tbody>
</table>
<p>330 rows Ã— 2 columns</p>
</div>

> åŒæ—¶ï¼Œåœ¨è¿›è¡Œæƒ…æ„Ÿåˆ†ææ—¶ï¼Œåº”å¢åŠ åœç”¨è¯`AAPL`.

**æ•°æ®å­˜å‚¨**ï¼šå­˜å‚¨ä¸º`è¡¥å……æ•°æ®1925102007/AAPLè®ºå›.csv`ã€‚

```python
# æ•°æ®å‚¨å­˜
forum.to_csv('è¡¥å……æ•°æ®1925102007/AAPLè®ºå›.csv', index=False)
```

#### 3.3.3 å…¨æ ‡é¢˜.xlsx

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>æ ‡é¢˜</th>
      <th>å­—æ®µ1_é“¾æ¥_é“¾æ¥</th>
      <th>ABOUT</th>
      <th>TIME</th>
      <th>AUTHOR</th>
      <th>COMMENTS</th>
      <th>Unnamed: 6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Micron Technology: Insanely Cheap Stock Given ...</td>
      <td>https://seekingalpha.com/article/4230920-micro...</td>
      <td>MU</td>
      <td>Dec. 31, 2018, 7:57 PM</td>
      <td>Ruerd Heeg</td>
      <td>75Â Comments</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Molson Coors Seems Attractive At These Valuations</td>
      <td>https://seekingalpha.com/article/4230922-molso...</td>
      <td>TAP</td>
      <td>Dec. 31, 2018, 7:44 PM</td>
      <td>Sanjit Deepalam</td>
      <td>16Â Comments</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Gerdau: The Brazilian Play On U.S. Steel</td>
      <td>https://seekingalpha.com/article/4230917-gerda...</td>
      <td>GGB</td>
      <td>Dec. 31, 2018, 7:10 PM</td>
      <td>Shannon Bruce</td>
      <td>1Â Comment</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>17925</th>
      <td>Big Changes For Centurylink, AT&amp;T And Verizon ...</td>
      <td>https://seekingalpha.com/article/4134687-big-c...</td>
      <td>CTL, T, VZ</td>
      <td>Jan. 1, 2018, 5:38 AM</td>
      <td>EconDad</td>
      <td>32Â Comments</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>17926</th>
      <td>UPS: If The Founders Were Alive Today</td>
      <td>https://seekingalpha.com/article/4134684-ups-f...</td>
      <td>UPS</td>
      <td>Jan. 1, 2018, 5:11 AM</td>
      <td>Roger Gaebel</td>
      <td>15Â Comments</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>17927</th>
      <td>U.S. Silica - Buying The Dip Of This Booming C...</td>
      <td>https://seekingalpha.com/article/4134664-u-s-s...</td>
      <td>SLCA</td>
      <td>Jan. 1, 2018, 12:20 AM</td>
      <td>The Value Investor</td>
      <td>27Â Comments</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>17928 rows Ã— 7 columns</p>
</div>

**ç´¢å¼•è¿‡æ»¤**ï¼šæå–æ‰€æœ‰`ABOUT`ä¸ºAAPLçš„æ ‡é¢˜æ•°æ®è¡Œã€‚

**é™ç»´å¤„ç†**ï¼šå­—æ®µ1\_é“¾æ¥\_é“¾æ¥ã€ABOUTã€AUTHORã€COMMENTSã€Unnamed: 6åˆ—åˆ é™¤ã€‚

**ç´¢å¼•é‡æ„**ï¼šé‡å‘½åç´¢å¼•ï¼Œæ ‡é¢˜-titleã€ABOUT-abbrã€TIME-dateã€‚

**æ—¶é—´åºåˆ—**ï¼šå°†dateè½¬åŒ–ä¸ºæ—¶é—´åºåˆ—ç´¢å¼•ï¼Œå¹¶æŒ‰æ­¤ç´¢å¼•å‡åºæ’åˆ—ã€‚

**æ•°æ®å­˜å‚¨**ï¼šå­˜å‚¨ä¸º`è¡¥å……æ•°æ®1925102007/AAPLå…¨æ ‡é¢˜.csv`ã€‚

```python
allTitles = pd.read_excel('å…¨æ ‡é¢˜.xlsx')
# ç´¢å¼•è¿‡æ»¤
allTitles = allTitles[allTitles['ABOUT']==CORPORATIONABBR]
# é™ç»´
allTitles.drop(['å­—æ®µ1_é“¾æ¥_é“¾æ¥',
                'ABOUT',
                'AUTHOR',
                'COMMENTS',
                'Unnamed: 6'], axis=1, inplace=True)
# ç´¢å¼•é‡æ„
AAPL_newIndex_allTitles = {'æ ‡é¢˜': 'title', 'TIME': 'date'}
allTitles.rename(columns=AAPL_newIndex_allTitles, inplace=True)
# æ—¶é—´åºåˆ—å¤„ç†
# å› æ—¶é—´æ—¥æœŸæ ¼å¼éç»Ÿä¸€ï¼Œæ•…é€‰ç”¨dateutilåŒ…å¯¹parser.parseæ–¹æ³•è¯†åˆ«å¤šå˜æ—¶é—´æ ¼å¼
allTitles['date'] = allTitles['date'].apply(lambda dt: dt_parse(dt))
# è®¾dateåˆ—ä¸ºç´¢å¼•
allTitles.set_index('date', inplace=True)
# æŒ‰dateå‡åºæ’åˆ—
allTitles.sort_values(by='date', inplace=True, ascending=True)
# æ•°æ®å‚¨å­˜
allTitles.to_csv('è¡¥å……æ•°æ®1925102007/AAPLå…¨æ ‡é¢˜.csv')
allTitles
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-01-04 10:12:00</th>
      <td>Apple Ia Above A 'Golden Cross' And Has A Posi...</td>
    </tr>
    <tr>
      <th>2018-01-08 10:59:00</th>
      <td>Apple Cash: What Would Warren Buffett Say?</td>
    </tr>
    <tr>
      <th>2018-01-16 06:34:00</th>
      <td>Apple's iPhone Battery Replacement Could Consu...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-12-31 08:52:00</th>
      <td>Will Apple Beat Its Guidance?</td>
    </tr>
    <tr>
      <th>2018-12-31 17:12:00</th>
      <td>How Much Stock Could Apple Have Repurchased In...</td>
    </tr>
    <tr>
      <th>2018-12-31 17:36:00</th>
      <td>Will Apple Get Its Mojo Back?</td>
    </tr>
  </tbody>
</table>
<p>204 rows Ã— 1 columns</p>
</div>

#### 3.3.4 æ‘˜è¦.xlsx

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>æ ‡é¢˜</th>
      <th>å­—æ®µ2</th>
      <th>å­—æ®µ5</th>
      <th>å­—æ®µ1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>HealthEquity: Strong Growth May Be Slowing Hea...</td>
      <td>Apr.  1, 2019 10:46 PM ET</td>
      <td>| About: HealthEquity, Inc. (HQY)</td>
      <td>SummaryHealthEquityâ€™s revenue and earnings hav...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Valero May Rally Up To 40% Within The Next 12 ...</td>
      <td>Apr.  1, 2019 10:38 PM ET</td>
      <td>| About: Valero Energy Corporation (VLO)</td>
      <td>SummaryValero is ideally positioned to benefit...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Apple Makes A China Move</td>
      <td>Apr.  1, 2019  7:21 PM ET</td>
      <td>| About: Apple Inc. (AAPL)</td>
      <td>SummaryCompany cuts prices on many key product...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10128</th>
      <td>Rubicon Technology: A Promising Net-Net Cash-B...</td>
      <td>Jul. 24, 2018  2:16 PM ET</td>
      <td>| About: Rubicon Technology, Inc. (RBCN)</td>
      <td>SummaryRubicon is trading well below likely li...</td>
    </tr>
    <tr>
      <th>10129</th>
      <td>Stamps.com: A Cash Machine</td>
      <td>Jul. 24, 2018  1:57 PM ET</td>
      <td>| About: Stamps.com Inc. (STMP)</td>
      <td>SummaryThe Momentum Growth Quotient for the co...</td>
    </tr>
    <tr>
      <th>10130</th>
      <td>Can Heineken Turn The 'Mallya Drama' In Its Ow...</td>
      <td>Jul. 24, 2018  1:24 PM ET</td>
      <td>| About: Heineken N.V. (HEINY), Includes: BUD,...</td>
      <td>SummaryMallya, United Breweries' chairman, can...</td>
    </tr>
  </tbody>
</table>
<p>10131 rows Ã— 4 columns</p>
</div>

ç»æ£€æŸ¥ï¼Œæ‘˜è¦.xlsxæ— ç¼ºå¤±å€¼ï¼Œæˆ‘ä»¬åªéœ€è¦æ ‡é¢˜å’Œå­—æ®µ1ï¼ˆæ‘˜è¦çš„å…¨æ–‡å­—å†…å®¹ï¼‰ï¼Œå…¶ä½™æ•°æ®åˆ—åˆ å»ã€‚å°†ç´¢å¼•æ˜ å°„ä¸ºï¼šæ ‡é¢˜-titleã€å­—æ®µ1-abstract. 

```python
abstracts = pd.read_excel('æ‘˜è¦.xlsx')
abstracts.drop(['å­—æ®µ2', 'å­—æ®µ5'], axis=1, inplace=True)
newIndex_abstracts = {'æ ‡é¢˜': 'title', 'å­—æ®µ1': 'abstract'}
abstracts.rename(columns=newIndex_abstracts, inplace=True)
```

**æ±‚äº¤é›†**ï¼šå’Œ`AAPLå…¨æ ‡é¢˜.csv`ä¸­titleç›¸å¯¹åº”çš„æ•°æ®è¡Œæ˜¯é’ˆå¯¹AAPLè‚¡ç¥¨å…¬å¸æ–‡ç« çš„æ‘˜è¦ï¼Œåªéœ€è¦å¯¹AAPLæ–‡ç« çš„æ‘˜è¦å³å¯ã€‚

```python
abstracts = abstracts.merge(allTitles, on=['title'], how='inner')
```

**ä¿å­˜**ï¼šå­˜å‚¨ä¸º`è¡¥å……æ•°æ®1925102007/AAPLæ‘˜è¦.csv`ã€‚

```python
abstracts.to_csv('è¡¥å……æ•°æ®1925102007/AAPLæ‘˜è¦.csv', index=False)
abstracts
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>abstract</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Will Apple Get Its Mojo Back?</td>
      <td>SummaryApple has been resting on a reputation ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>How Much Stock Could Apple Have Repurchased In...</td>
      <td>SummaryApple's stock plummeted from $227.26 to...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Will Apple Beat Its Guidance?</td>
      <td>SummaryApple has sold fewer iPhones, which gen...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>83</th>
      <td>Apple: Still The Ultimate Value Growth Stock T...</td>
      <td>SummaryApple reported superb earnings on Tuesd...</td>
    </tr>
    <tr>
      <th>84</th>
      <td>Apple In 2023</td>
      <td>SummaryWhere can the iPhone go from here?The A...</td>
    </tr>
    <tr>
      <th>85</th>
      <td>Apple's Real Value Today</td>
      <td>SummaryApple has reached new highs this week.W...</td>
    </tr>
  </tbody>
</table>
<p>86 rows Ã— 2 columns</p>
</div>

#### 3.3.5 å›å¸–

```python
pd.read_excel('å›å¸–/SA_Comment_Page131-153.xlsx')
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>å­—æ®µ</th>
      <th>æ ‡é¢˜1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>you should all switch to instagram</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Long Facebook and Instagram. They will recover...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Personally, I think people will be buying FB a...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19968</th>
      <td>Thank you for the article.If you really think ...</td>
      <td>Qiwi: The Current Sell-Off Was Too Emotional</td>
    </tr>
    <tr>
      <th>19969</th>
      <td>Isn't WRK much better investment than PKG? Thanks</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>19970</th>
      <td>GuruFocus is also showing a Priotroski score o...</td>
      <td>Packaging Corporation Of America: Target Retur...</td>
    </tr>
  </tbody>
</table>
<p>19971 rows Ã— 2 columns</p>
</div>

```python
pd.read_csv('å›å¸–/SA_Comment_Page181-255(1).csv')
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>å­—æ®µ1</th>
      <th>æ ‡é¢˜</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>I bought at $95 and holding strong. Glad I did...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The price rally you are referring to is not be...</td>
      <td>Michael Kors: Potential For Further Upside Ahead</td>
    </tr>
    <tr>
      <th>2</th>
      <td>only a concern if you own it....</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>19997</th>
      <td>What can Enron Musk do legally to boost  balan...</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>19998</th>
      <td>The last two weeks feels like a short squeeze....</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>19999</th>
      <td>" Tesla is no longer a growth or value proposi...</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>20000 rows Ã— 2 columns</p>
</div>

ç´¢å¼•é‡å‘½åï¼šå­—æ®µ1ï¼ˆå›å¸–å†…å®¹ï¼‰-contentã€æ ‡é¢˜-title.ï¼ˆæ³¨æ„.csvå’Œ.xlsxä¸åŒï¼‰

ç¼ºå¤±å€¼å¤„ç†ï¼šå¯¹äºå›å¸–ä¸­æ ‡é¢˜1ï¼ˆå„æ–‡ç« æ ‡é¢˜ï¼‰çš„å®šä¹‰ç©ºæ ‡é¢˜çš„ï¼Œç”¨æœ€é è¿‘çš„æœ‰å†…å®¹çš„ä¸‹æ–¹æ ‡é¢˜ï¼Œæ•…é‡‡å–ç”¨ä¸‹ä¸€ä¸ªéç¼ºå¤±å€¼å¡«å……å‰ç¼ºå¤±å€¼çš„æ–¹æ³•`df.fillna(method='bfill')`ã€‚

æ•°æ®æ–‡ä»¶è¯»å–ï¼šä½¿ç”¨`os.listdir()`è¿”å›æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹åŒ…å«çš„æ–‡ä»¶ååˆ—è¡¨ï¼Œä»¥.xlsxæˆ–.csvç»“å°¾çš„æ–‡ä»¶å‡ä¸ºæ•°æ®æ–‡ä»¶ï¼Œè¯»å…¥åè¿›è¡Œä¸Šè¿°ç¼ºå¤±å€¼å¤„ç†å’Œç´¢å¼•é‡å‘½åã€‚

å›å¸–è¿‡æ»¤ï¼šéå†æ‰€æœ‰æ•°æ®æ–‡ä»¶ï¼Œæ‰¾å‡ºæ‰€æœ‰titleåœ¨`AAPLå…¨æ ‡é¢˜.csv`ä¸­çš„å›å¸–è¡Œæ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±ï¼Œå­˜è‡³`è¡¥å……æ•°æ®1925102007/AAPLå›å¸–.csv`

```python
# æ•°æ®æ–‡ä»¶è¯»å–
repliesFiles = listdir('å›å¸–')
allAALPReplies = []
newIndex_replies_csv = {'å­—æ®µ1': 'content', 'æ ‡é¢˜': 'title'}
newIndex_replies_xlsx = {'å­—æ®µ': 'content', 'æ ‡é¢˜1': 'title'}
# éå†å›å¸–ç›®å½•ä¸‹æ‰€æœ‰å›å¸–æ•°æ®æ‰¾å‡ºå’ŒAAPLç›¸å…³çš„å›å¸–
for file in repliesFiles:
    path = 'å›å¸–/'+file
    if file.endswith('.csv'):
        replies = pd.read_csv(path)
        newIndex_replies = newIndex_replies_csv
    elif file.endswith('.xlsx'):
        replies = pd.read_excel(path)
        newIndex_replies = newIndex_replies_xlsx
    else:
        print('Wrong file format,', file)
        break
    # ç´¢å¼•é‡å‘½å
    replies.rename(columns=newIndex_replies, inplace=True)
    # ç¼ºå¤±å€¼å¡«å……
    replies.fillna(method='bfill', inplace=True)
    # å›å¸–è¿‡æ»¤
    allAALPReplies.extend(replies.merge(allTitles, on=['title'], how='inner').values)
# æ‰€æœ‰å’ŒAAPLæ–‡ç« æ ‡é¢˜æ‰€å¯¹åº”çš„å›å¸–
allAALPReplies = pd.DataFrame(allAALPReplies, columns=['content', 'title'])
# ä¿å­˜
allAALPReplies.to_csv('è¡¥å……æ•°æ®1925102007/AAPLå›å¸–.csv', index=False)
# å±•ç¤º
allAALPReplies
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>content</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Understood. But let me ask you. 64GB of pics i...</td>
      <td>iPhone XR And XS May Be Apple's Most Profitabl...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Just upgraded from 6 to XS, 256G. Love it. I'l...</td>
      <td>iPhone XR And XS May Be Apple's Most Profitabl...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Yup, AAPL will grow profits 20% per year despi...</td>
      <td>iPhone XR And XS May Be Apple's Most Profitabl...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4503</th>
      <td>With all due respect, never have paid for and ...</td>
      <td>Gain Exposure To Apple Through Berkshire Hathaway</td>
    </tr>
    <tr>
      <th>4504</th>
      <td>This one's easy - own both!</td>
      <td>Gain Exposure To Apple Through Berkshire Hathaway</td>
    </tr>
    <tr>
      <th>4505</th>
      <td>No Thanks! I like my divys,and splits too much...</td>
      <td>Gain Exposure To Apple Through Berkshire Hathaway</td>
    </tr>
  </tbody>
</table>
<p>4506 rows Ã— 2 columns</p>
</div>

### 3.4 æƒ…æ„Ÿåˆ†æ

> ä½¿ç”¨ç¬¬ä¸‰æ–¹NLPåº“ï¼š**NLTK** (Natural Language Toolkit)
>
> NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries. 
>
> **å®‰è£…å®Œnltkåº“ä»¥åï¼Œéœ€è¦ä½¿ç”¨`nltk.download()`å‘½ä»¤ä¸‹è½½ç›¸åº”è¯­æ–™åº“ã€‚å› ä¸ºé€Ÿåº¦å¤ªæ…¢ï¼Œæˆ‘é€‰æ‹©ç›´æ¥è£…nltk_dataæ•°æ®åŒ…ï¼Œæ ¸å¿ƒæ•°æ®åŒ…æ”¾åœ¨è¡¥å……æ–‡ä»¶å¤¹å†…ã€‚**
>
> **ä¸ºæé«˜æƒ…æ„Ÿåˆ†ææ•ˆç‡å’Œç²¾åº¦ï¼Œåœç”¨è¯è¿˜éœ€å¢åŠ `['!', ',' ,'.' ,'?' ,'-s' ,'-ly' ,'</s> ', 's', 'AAPL', 'apple', '$', '%']`. ä½¿ç”¨`stopwords.add()`æ·»åŠ åœç”¨è¯ã€‚**
>
> [Source3] http://www.nltk.org

> é‡‘èæƒ…æ„Ÿè¯åº“ï¼š**LM** (LoughranMcDonald) sentiment word lists 2018
>
> [Loughran-McDonald Sentiment Word Lists](https://sraf.nd.edu/textual-analysis/resources/#LM Sentiment Word Lists) is an Excel file containing each of the LM sentiment words by category (Negative, Positive, Uncertainty, Litigious, Strong Modal, Weak Modal, Constraining).
>
> è¯åº“è·¯å¾„ï¼š`/è¡¥å……æ•°æ®1925102007/LoughranMcDonald_SentimentWordLists_2018.xlsx`
>
> [Source4] https://sraf.nd.edu/textual-analysis/resources

#### 3.4.1 æƒ…æ„Ÿåˆ†ææ€è·¯

* **åˆ†è¯å¤„ç†**ï¼šä½¿ç”¨NLTKå¯¹æ–‡æœ¬ï¼ˆè¿™é‡ŒæŒ‡è¯„è®ºæ•°æ®ï¼‰è¿›è¡Œåˆ†è¯å¤„ç†ï¼ˆtokenizeï¼‰
* **åœç”¨è¯å¤„ç†**ï¼šå»é™¤åœç”¨è¯ï¼ˆstopwordsï¼‰
* **ç»“æ„åŒ–**ï¼šåˆ©ç”¨LMé‡‘èæƒ…æ„Ÿè¯åº“ä¸­çš„Positiveå’ŒNegativeè¡¨å•è¯åº“ï¼Œè®¡ç®—`pos`å’Œ`neg`å€¼ä½œä¸ºéç»“æ„åŒ–æ–‡æœ¬æ•°æ®çš„ç»“æ„åŒ–ç‰¹å¾ã€‚ï¼ˆ*å³ä»¥è¯„è®ºä¸­posWordså’ŒnegWordsçš„å æ¯”ä½œä¸ºæ–‡æœ¬æ•°æ®çš„ç‰¹å¾*ï¼‰
* **æ•°æ®èšåˆ**ï¼šå¯¹ä¸Šè¿°æ•°æ®è¿›è¡Œèšåˆæ“ä½œï¼Œå¹¶æŒ‰å·¥ä½œæ—¥ï¼ˆè‚¡ç¥¨çš„äº¤æ˜“æ—¶é—´æ˜¯`Business Day`ï¼‰ä¸ºå•ä½è¿›è¡Œé‡é‡‡æ ·

$$
pos = \frac{Num of PosWrods}{Total Words}
$$

$$
neg = \frac{Num of NegWrods}{Total Words}
$$

#### 3.4.2 è¯åº“å¯¼å…¥å’Œæ·»åŠ åœç”¨è¯

```python
# è¯åº“å¯¼å…¥
wordListsPath = 'è¡¥å……æ•°æ®1925102007/LoughranMcDonald_SentimentWordLists_2018.xlsx'
posWords = pd.read_excel(wordListsPath, header=None, sheet_name='Positive').iloc[:,0].values
negWords = pd.read_excel(wordListsPath, header=None, sheet_name='Negative').iloc[:,0].values

# æ·»åŠ åœç”¨è¯
extraStopwords = ['!', ',' ,'.' ,'?' ,'-s' ,'-ly' ,'</s> ', 's', 'AAPL', 'apple', '$', '%']
stopWs = stopwords.words('english') + extraStopwords
```

#### 3.4.3 å‡½æ•°å®šä¹‰

```python
def structComment(sentence, posW, negW, stopW):
    """
    ç»“æ„åŒ–å¥å­
    :param sentence: å¾…ç»“æ„åŒ–çš„è¯„è®º
    :param posW: æ­£è¯æ€§
    :param negW: è´Ÿè¯æ€§
    :param stopW: åœç”¨è¯
    :return: å»é™¤åœç”¨è¯åçš„è¯„è®ºä¸­posWordså’ŒnegWordsçš„å æ¯”(pos, neg)
    """
    # åˆ†è¯
    tokenizer = nltk.word_tokenize(sentence)
    # åœç”¨è¯è¿‡æ»¤
    tokenizer = [w.upper() for w in tokenizer if w.lower() not in stopW]
    # æ­£è¯æå–
    posWs = [w for w in tokenizer if w in posW]
    # è´Ÿè¯æå–
    negWs = [w for w in tokenizer if w in negW]
    # tokenizeré•¿åº¦
    len_token = len(tokenizer)
    # å¥å­é•¿åº¦ä¸º0ï¼Œå³åˆ†æ¯ä¸º0æ—¶
    if len_token<=0:
        return 0, 0
    else:
        return len(posWs)/len_token, len(negWs)/len_token
```

```python
def NLProcessing(fileName, colName):
    """
    è‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•ï¼šå°†ä¼ å…¥çš„fileName(.csv)å¯¹åº”çš„æ•°æ®ä¸­çš„colNameåˆ—æ–‡æœ¬æ•°æ®ç»“æ„åŒ–ï¼Œå¹¶ä¿å­˜
    :param fileName: æ–‡ä»¶åï¼Œåœ¨æ–‡ä»¶å¤¹ è¡¥å……æ•°æ®1925102007/ ä¸‹æŸ¥æ‰¾å¯¹åº”æ–‡ä»¶
    :param colName: éœ€è¦ç»“æ„åŒ–çš„æ–‡æœ¬æ•°æ®åˆ—
    :return: æ–°å¢poså’Œnegåˆ—çš„DataFrame
    """
    pathNLP = 'è¡¥å……æ•°æ®1925102007/'+fileName+'.csv'
    data = pd.read_csv(pathNLP)
    # poså’Œnegç»“æ„åŒ–æ•°æ®åˆ—æ„é€ 
    posAndneg = [ structComment(st, posWords, negWords, stopWs) for st in data[colName].values]
    # æ„é€ posAndnegçš„DataFrame
    posAndneg = pd.DataFrame(posAndneg, columns=['pos', 'neg'])
    # è½´å‘è¿æ¥
    data = pd.concat([data, posAndneg], axis=1)
    # åˆ é™¤æ–‡æœ¬æ•°æ®åˆ—
    data.drop([colName], axis=1, inplace=True)
    # ä¿å­˜ç»“æ„åŒ–çš„æ•°æ®
    data.to_csv(pathNLP)
    return data
```

#### 3.4.4 æƒ…æ„Ÿåˆ†æå¤„ç†

```python
# AAPLè®ºå›.csv
forum = NLProcessing('AAPLè®ºå›', 'remark')
# AAPLæ‘˜è¦.csv
abstracts = NLProcessing('AAPLæ‘˜è¦', 'abstract')
# AAPLå›å¸–.csv
allAALPReplies = NLProcessing('AAPLå›å¸–', 'content')
```

#### 3.4.5 æƒ…æ„Ÿç‰¹å¾æ•°æ®èšåˆ

ä¸Šè¿°æ“ä½œå¾—åˆ°å¸¦æœ‰titleåˆ—çš„ç»“æ„åŒ–æ•°æ®ï¼ˆAAPLå›å¸–.csvå’ŒAAPLæ‘˜è¦.csvï¼‰åï¼Œå…ˆå°†å›å¸–å’Œæ‘˜è¦ç”¨concatå‡½æ•°æ²¿çºµè½´è¿æ¥ï¼Œå†ä»¥titleä¸ºç´¢å¼•ï¼Œä¸AAPLå…¨æ ‡é¢˜.csvï¼ˆallTitlesï¼‰è¿›è¡Œå¤–è”åˆå¹¶ï¼ˆOuter Mergeï¼‰ï¼Œåˆ é™¤æ— ç”¨çš„titleåˆ—ã€‚forumç»“æ„åŒ–æ•°æ®å’Œä¸Šä¸€æ­¥æ‰€å¾—æ•°æ®è¿›è¡Œconcatè½´ç›¸è¿æ¥ï¼ˆæ²¿çºµè½´ï¼‰ã€‚æœ€åï¼Œä»¥æ—¶é—´å¤©ä¸ºå•ä½è¿›è¡Œé‡é‡‡æ ·ï¼Œå¾—å‡ºæ¯æ—¥çš„poså’Œnegç‰¹å¾çš„å¹³å‡å€¼ã€‚

```python
# è½´ç›¸è¿æ¥abstractså’ŒallAALPReplies
allEssaysComment = pd.concat([abstracts,allAALPReplies], ignore_index=True)
# è”è¡¨
allEssaysComment = allTitles.merge(allEssaysComment, how='outer', on='title')
# åˆ é™¤ç¼ºå¤±è¡Œ
allEssaysComment.dropna(inplace=True)
# åˆ é™¤titleåˆ—
allEssaysComment.drop('title', axis=1, inplace=True)
# å’Œforumæƒ…æ„Ÿæ•°æ®è¿›è¡Œè½´å‘è¿æ¥
allEssaysComment = pd.concat([allEssaysComment,forum], ignore_index=True)
# åˆ é™¤poså’Œnegå‡ä¸º0çš„æ— ç”¨æ•°æ®è¡Œ
allEssaysComment = allEssaysComment[(allEssaysComment['pos']+allEssaysComment['neg'])>0]

# è®¾dateä¸ºæ—¶é—´åºåˆ—ç´¢å¼•
allEssaysComment['date'] = pd.to_datetime(allEssaysComment['date'])
allEssaysComment.set_index('date', inplace=True)
# æŒ‰"å·¥ä½œæ—¥"é‡é‡‡æ ·ï¼Œæ±‚poså’Œnegçš„å‡å€¼ï¼Œä¸å­˜åœ¨çš„å¤©ä»¥0å¡«å……
allEssaysComment = allEssaysComment.resample('B').mean()
allEssaysComment.fillna(0, inplace=True)
# å‚¨å­˜
allEssaysComment.to_csv('è¡¥å……æ•°æ®1925102007/allPosAndNeg.csv')
# å±•ç¤º
allEssaysComment
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pos</th>
      <th>neg</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-01-05</th>
      <td>0.041667</td>
      <td>0.043478</td>
    </tr>
    <tr>
      <th>2018-01-08</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2018-01-09</th>
      <td>0.000000</td>
      <td>0.090909</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-12-24</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2018-12-25</th>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2018-12-26</th>
      <td>0.090909</td>
      <td>0.090909</td>
    </tr>
  </tbody>
</table>
<p>254 rows Ã— 2 columns</p>
</div>

### 3.5 \* èå…¥æƒ…æ„Ÿæ•°æ®çš„è‚¡ç¥¨æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ

**æ–¹æ³•**ï¼šå¸Œæœ›å€ŸåŠ©seabornçš„`pairplot`å‡½æ•°ç»˜åˆ¶AAPLè‚¡ç¥¨ä»·æ ¼.csvï¼ˆsharePricesAAPLï¼‰çš„å„é¡¹æŒ‡æ ‡æ•°æ®ä¸¤ä¸¤å…³è”çš„æ•£ç‚¹å›¾ï¼ˆå¯¹è§’çº¿ä¸ºå˜é‡çš„ç›´æ–¹å›¾ï¼‰ï¼Œä»è€Œæ¢ç©¶ä¸åŒæŒ‡æ ‡é—´çš„å…³ç³»ã€‚

**ç›®çš„**ï¼šåˆ†æè‚¡ç¥¨å„æŒ‡æ ‡é—´çš„å…³ç³»ã€‚ä»¥åŠæ˜¯å¦æ‰¾å‡ºçº¿æ€§ç›¸å…³ç¨‹åº¦é«˜çš„æŒ‡æ ‡ï¼Œåˆ é™¤ä¹‹ï¼Œä»¥å‡å°‘LSTMçš„è®­ç»ƒæ—¶é—´æˆæœ¬ã€‚

> pairplotå‡½æ•°æ–‡æ¡£ï¼šhttp://seaborn.pydata.org/generated/seaborn.pairplot.html

#### 3.5.1 æ•°æ®è”åˆ

å°†2.2æ‰€å¾—æ—¶é—´åºåˆ—æƒ…æ„Ÿåˆ†ææ•°æ®ï¼ˆ`allPosAndNeg.csv`ï¼‰å’Œ`AAPLè‚¡ç¥¨ä»·æ ¼.csv`ï¼ˆsharePricesAAPLï¼‰ä»¥dateä¸ºç´¢å¼•åˆå¹¶ã€‚

> è”åˆæ—¶å¯ä»¥å‘ç°ï¼Œè¯„è®ºæ•°æ®çš„æ—¶é—´è·¨åº¦è¶³ä»¥è¦†ç›–AAPLè‚¡ç¥¨ä»·æ ¼æ•°æ®ï¼Œæ‰€ä»¥ä¸ç”¨æ‹…å¿ƒç¼ºå¤±å€¼çš„é—®é¢˜ã€‚ <a id="mark1" href="#mark2">[Jump to relative contents]</a>

```python
# æ–‡ä»¶è¯»å–
sharePricesAAPL = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼.csv')
allPosAndNeg = pd.read_csv('è¡¥å……æ•°æ®1925102007/allPosAndNeg.csv')
# åˆå¹¶
sharePricesAAPLwithEmotion = sharePricesAAPL.merge(allPosAndNeg, how='inner', on='date')
# åºåˆ—åŒ–æ—¶é—´ç´¢å¼•date
sharePricesAAPLwithEmotion['date'] = pd.DatetimeIndex(sharePricesAAPLwithEmotion['date'])
sharePricesAAPLwithEmotion.set_index('date', inplace=True)
# reindex
AAPL_newColOrder_emotionPrices = ['open', 
                                  'high', 
                                  'low', 
                                  'vol', 
                                  'pos', 
                                  'neg', 
                                  'close']
sharePricesAAPLwithEmotion = sharePricesAAPLwithEmotion.reindex(columns=AAPL_newColOrder_emotionPrices)
# ä¿å­˜
sharePricesAAPLwithEmotion.to_csv('è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼èåˆæƒ…æ„Ÿ.csv')
```

#### 3.5.2 pairplotç»˜å›¾

**ç•™ä¸‹å¿…è¦çš„OHLCæŠ€æœ¯æŒ‡æ ‡ï¼Œå¯¹å‰©ä½™çš„volã€posã€negè¿›è¡Œç›¸å…³æ€§åˆ†æç»˜å›¾**

> å®éªŒæ—¶ï¼Œæˆ‘ä¹Ÿç»˜åˆ¶äº†OHLCæŠ€æœ¯æŒ‡æ ‡çš„è½´çº¿ç½‘æ ¼å›¾ï¼Œå¯ä»¥å‘ç°ï¼Œå…¶ä¸¤ä¸¤é—´å…·æœ‰è¾ƒé«˜çš„çº¿æ€§ç›¸å…³æ€§ã€‚

```python
# Parameters:
# data: pandas.DataFrame [Tidy (long-form) dataframe where each column is a variable and each row is an observation.]
# diag_kind: {â€˜autoâ€™, â€˜histâ€™, â€˜kdeâ€™, None} [Kind of plot for the diagonal subplots.]
# kind: {â€˜scatterâ€™, â€˜kdeâ€™, â€˜histâ€™, â€˜regâ€™} [Kind of plot to make.]
fig1 = pairplot(sharePricesAAPLwithEmotion[['vol', 'pos', 'neg']], diag_kind='hist', kind='reg')
# save the fig1 to è¡¥å……æ•°æ®1925102007/
fig1.savefig('è¡¥å……æ•°æ®1925102007/fig1_a_Grid_of_Axes.png')
```

![fig1_a_Grid_of_Axes.png](fig1_a_Grid_of_Axes.png)

#### 3.5.3 è‚¡ç¥¨æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ

è§‚å¯Ÿæ‰€å¾—`Fig1: a Grid of Axes `ä¸éš¾å‘ç°ï¼ŒæŒ‡æ ‡volã€posã€negä¹‹é—´çº¿æ€§ç›¸å…³æ€§è¾ƒå¼±ï¼Œæ‰€ä»¥å‡ä¿ç•™ï¼Œä½œä¸ºLSTMé¢„æµ‹æŒ‡æ ‡ã€‚

### 3.6 LSTMé¢„æµ‹èåˆæƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®

**ä¾èµ–çš„åº“**ï¼šKerasã€Sklearnã€Tensorflow <a id="toref4" href="#ref4">[4]</a>

**é¢„æµ‹ç›®æ ‡**ï¼š`close`ï¼ˆæ”¶ç›˜ä»·ï¼‰

> **å¼•ç”¨å‡½æ•°**ï¼š`series_to_supervised(data, n_in=1, n_out=1, dropnan=True)`
>
> æ¥æºï¼š[Time Series Forecasting With Python](https://machinelearningmastery.com/introduction-to-time-series-forecasting-with-python/)
>
> ç”¨é€”ï¼šFrame a time series as a supervised learning dataset. å°†è¾“å…¥çš„å•å˜é‡æˆ–å¤šå˜é‡æ—¶é—´åºåˆ—è½¬åŒ–ä¸ºæœ‰ç›‘ç£å­¦ä¹ æ•°æ®é›†ã€‚
>
> å‚æ•°ï¼ˆArgumentsï¼‰ï¼š
>
> > data: Sequence of observations as a list or NumPy array.
> >
> > n_in: Number of lag observations as input (X).
> >
> > n_out: Number of observations as output (y).
> >
> > dropnan: Boolean whether or not to drop rows with NaN values.
> >
> > **\# å› ä¸ºLSTMå·²ç»å…·æœ‰è®°å¿†åŠŸèƒ½äº†ï¼Œæ‰€ä»¥æˆ‘çš„n_inå’Œn_outå‚æ•°ç›´æ¥ä½¿ç”¨é»˜è®¤çš„1å³å¯ï¼ˆä¹Ÿå°±æ˜¯æ„é€ [t-1]ç°æ€åˆ—å’Œ[t]æ¬¡æ€åˆ—ï¼‰ã€‚**
>
> è¿”å›å€¼ï¼ˆReturnsï¼‰ï¼š
>
> > Pandas DataFrame of series framed for supervised learning.

#### 3.6.1 æ—¶é—´åºåˆ—è½¬æœ‰ç›‘ç£å‡½æ•°å®šä¹‰

```python
def series_to_supervised(data, n_in=1):
    # é»˜è®¤å‚æ•°
    n_out=1
    dropnan=True
    # å¯¹è¯¥å‡½æ•°è¿›è¡Œå¾®è°ƒï¼Œæ³¨æ„dataä¸ºä»¥closeåˆ—ï¼ˆéœ€è¦é¢„æµ‹çš„åˆ—ï¼‰ç»“å°¾çš„DataFrameæ—¶é—´åºåˆ—è‚¡ç¥¨æ•°æ®
    n_vars = 1 if type(data) is list else data.shape[1]
    df = pd.DataFrame(data)
    cols, names = list(), list()
    # input sequence (t-n, ... t-1)
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
    # forecast sequence (t, t+1, ... t+n)
    for i in range(0, n_out):
        cols.append(df.shift(-i))
        if i == 0:
            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
        else:
            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
    # put it all together
    agg = pd.concat(cols, axis=1)
    agg.columns = names
    # åˆ é™¤æ— å…³çš„æ¬¡æ€[t]åˆ—ï¼Œåªç•™ä¸‹éœ€è¦é¢„æµ‹çš„close[t]åˆ—å’Œä¸Šä¸€æ—¶åˆ»çŠ¶æ€ç‰¹å¾[t-1]åˆ—
    agg.drop(agg.columns[[x for x in range(data.shape[1], 2*data.shape[1]-1)]], axis=1, inplace=True)
    # drop rows with NaN values
    if dropnan:
        agg.dropna(inplace=True)
    return agg
```

#### 3.6.2 èåˆæƒ…æ„Ÿçš„è‚¡ç¥¨æ•°æ®å½’ä¸€åŒ–

```python
# è¯»å–æ•°æ®
sharePricesAAPLwithEmotion = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼èåˆæƒ…æ„Ÿ.csv', parse_dates=['date'], index_col='date').values
# ç”Ÿæˆå½’ä¸€åŒ–å®¹å™¨
# feature_rangeå‚æ•°æ²¿ç”¨é»˜è®¤(0,1)
scaler = MinMaxScaler()
# è®­ç»ƒæ¨¡å‹
scaler = scaler.fit(sharePricesAAPLwithEmotion)
# å½’ä¸€åŒ–
sharePricesAAPLwithEmotion = scaler.fit_transform(sharePricesAAPLwithEmotion)
# éƒ¨åˆ†ç»“æœå±•ç¤º
sharePricesAAPLwithEmotion[:5,:]
```

    array([[0.4316836 , 0.43640137, 0.44272148, 0.06118638, 0.        ,
            0.        , 0.47336914],
           [0.47972885, 0.44433594, 0.44416384, 0.01698249, 0.        ,
            0.        , 0.4351243 ],
           [0.44911044, 0.42553711, 0.45305926, 0.04901593, 0.        ,
            0.        , 0.45248692],
           [0.4510469 , 0.45024426, 0.46411828, 0.05954544, 0.        ,
            0.        , 0.4826372 ],
           [0.50042364, 0.47766101, 0.51340305, 0.08659896, 0.        ,
            0.        , 0.51325663]])

#### 3.6.3 æ—¶é—´åºåˆ—æ„å»ºæœ‰ç›‘ç£æ•°æ®é›†

```python
# ä½¿ç”¨series_to_supervisedå‡½æ•°æ„å»ºæœ‰ç›‘ç£æ•°æ®é›†
sharePricesAAPLwithEmotion = series_to_supervised(sharePricesAAPLwithEmotion)
sharePricesAAPLwithEmotion
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>var1(t-1)</th>
      <th>var2(t-1)</th>
      <th>var3(t-1)</th>
      <th>var4(t-1)</th>
      <th>var5(t-1)</th>
      <th>var6(t-1)</th>
      <th>var7(t-1)</th>
      <th>var7(t)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.431684</td>
      <td>0.436401</td>
      <td>0.442721</td>
      <td>0.061186</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.473369</td>
      <td>0.435124</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.479729</td>
      <td>0.444336</td>
      <td>0.444164</td>
      <td>0.016982</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.435124</td>
      <td>0.452487</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.449110</td>
      <td>0.425537</td>
      <td>0.453059</td>
      <td>0.049016</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.452487</td>
      <td>0.482637</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>120</th>
      <td>0.148251</td>
      <td>0.128906</td>
      <td>0.104700</td>
      <td>0.624252</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.117316</td>
      <td>0.045753</td>
    </tr>
    <tr>
      <th>121</th>
      <td>0.105410</td>
      <td>0.080688</td>
      <td>0.036543</td>
      <td>0.994059</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.045753</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>122</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.295643</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.121305</td>
    </tr>
  </tbody>
</table>
<p>122 rows Ã— 8 columns</p>
</div>

#### 3.6.4 è®­ç»ƒé›†éªŒè¯é›†åˆ’åˆ†

```python
# å¿…é¡»è§„å®šndarrayçš„dtypeä¸ºfloat32ï¼ˆé»˜è®¤float64ï¼‰ï¼Œå¦åˆ™åç»­è¾“å…¥LSTMæ¨¡å‹æŠ¥é”™
sharePricesAAPLwithEmotion = sharePricesAAPLwithEmotion.values.astype(np.float32)
# è®­ç»ƒé›†:éªŒè¯é›†=7:3
X_train, X_test, y_train, y_test = train_test_split(sharePricesAAPLwithEmotion[:,:-1], sharePricesAAPLwithEmotion[:,-1], test_size=0.3, shuffle=False)
```

#### 3.6.5 åŸºäºKerasçš„LSTMæ¨¡å‹æ­å»º

> å‚è€ƒæ–‡æ¡£ï¼š
>
> [Keras core: Dense and Dropout](https://keras.io/zh/layers/core/)
>
> [Keras Activation relu](https://keras.io/zh/activations/#relu)
>
> [Keras Losses mean_squared_error](https://keras.io/zh/losses/#mean_squared_error)
>
> [Keras Optimizer adam](https://keras.io/zh/optimizers/#adam)
>
> [Keras LSTM Layers](https://keras.io/api/layers/recurrent_layers/lstm/)
>
> [Keras Sequential Model](https://keras.io/guides/sequential_model/)

##### 3.6.5 (ä¸€)ã€é‡å¡‘LSTMçš„è¾“å…¥X

> LSTMçš„è¾“å…¥æ ¼å¼ä¸º**`shape = [samples,timesteps,features]`**ï¼š
>
> samplesï¼šæ ·æœ¬æ•°é‡
>
> timestepsï¼šæ—¶é—´æ­¥é•¿
>
> features (input_dim)ï¼šæ¯ä¸€ä¸ªæ—¶é—´æ­¥ä¸Šçš„ç»´åº¦

é‡å¡‘`X_train`å’Œ`X_test`ï¼š

```python
# reshape input to be 3D [samples, timesteps, features]
X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))
```

##### 3.6.5 (äºŒ)ã€æ­å»ºLSTMæ¨¡å‹å¹¶ç»˜åˆ¶æŸå¤±å›¾

* å»ºç«‹Sequentialæ¨¡å‹
* æ·»åŠ LSTMå±‚ï¼ˆ`64`ä¸ªéšè—å±‚ç¥ç»å…ƒï¼Œ`1`ä¸ªè¾“å‡ºå±‚ç¥ç»å…ƒï¼ŒæŒ‡å®šå¤šå±‚LSTMæ¨¡å‹ç¬¬ä¸€å±‚çš„`input_shape`å‚æ•°ï¼‰*å›å½’æ¨¡å‹*
* è®¾å®šDropoutåœ¨æ¯æ¬¡è®­ç»ƒæ—¶çš„ä¸¢å¼ƒæ¯”ï¼ˆrateï¼‰ä¸º`0.4`
* è®¾å®šDenseå…¨è¿æ¥å±‚çš„è¾“å‡ºç©ºé—´ç»´åº¦ï¼ˆunitsï¼‰ä¸º`1`ï¼Œæ¿€æ´»å‡½æ•°ï¼ˆactivationï¼‰ä¸º`relu`ï¼ˆæ•´æµçº¿æ€§å•å…ƒï¼‰
* è®¾å®šSequentialçš„æŸå¤±å‡½æ•°ï¼ˆlossï¼‰ä¸º`MSE`ï¼ˆMean-Square Errorï¼‰å‡æ–¹è¯¯å·®ï¼Œä¼˜åŒ–å™¨ï¼ˆoptimizerï¼‰ä¸º`adam`
* æ¨¡å‹è®­ç»ƒè®¾ç½®`epochs=50; batch_size=30`

```python
def LSTMModelGenerate(Xtrain, Xtest, ytrain, ytest):
    """
    LSTMæ¨¡å‹æ­å»ºå‡½æ•°
    :param Xtrain: è®­ç»ƒé›†å±æ€§
    :param Xtest: æµ‹è¯•é›†å±æ€§
    :param ytrain: è®­ç»ƒé›†æ ‡ç­¾
    :param ytest: æµ‹è¯•é›†æ ‡ç­¾
    :return: history,modelï¼ˆæ¨¡å‹ç¼–è¯‘è®°å½•å’Œæ¨¡å‹ï¼‰
    """
    # æ­å»ºLSTMæ¨¡å‹
    _model = Sequential()
    _model.add(LSTM(64, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))
    _model.add(Dropout(0.4))
    _model.add(Dense(1, activation='relu'))
    # æ¨¡å‹ç¼–è¯‘
    _model.compile(loss='mse', optimizer='adam')
    # æ¨¡å‹è®­ç»ƒ
    _history = _model.fit(Xtrain, ytrain, epochs=50, batch_size=30, validation_data=(Xtest, ytest), shuffle=False, verbose=0)
    return _history,_model
  
history, model = LSTMModelGenerate(X_train, X_test, y_train, y_test)
```

* æŸå¤±å›¾ç»˜åˆ¶

```python
def drawLossGraph(_history, title, num):
    """
    æŸå¤±å›¾ç»˜åˆ¶ï¼Œå¯»æ‰¾æœ€ä¼˜epochs
    :param _history: è®­ç»ƒå†å²
    :param title: å›¾è¡¨æ ‡é¢˜
    :param num: å›¾è¡¨ç¼–å·
    :return: æ— 
    """
    plt.plot(_history.history['loss'], color='g', label='train')
    plt.plot(_history.history['val_loss'], color='r', label='test')
    plt.title('Fig'+num+'. '+title)
    plt.xlabel('epochs')
    plt.ylabel('loss')
    plt.legend()
    # ä¿å­˜äº è¡¥å……æ•°æ®1925102007/
    savingPath = 'è¡¥å……æ•°æ®1925102007/fig'+num+'_'+title.replace(' ', '_')+'.png'
    plt.savefig(savingPath, dpi=400, bbox_inches='tight')
    # å±•ç¤º
    plt.show()
    
drawLossGraph(history, title='LSTM Loss Graph for Stock Prices with Emotions', num='2')
```

![fig2_LSTM_Loss_Graph_for_Stock_Prices_with_Emotions](fig2_LSTM_Loss_Graph_for_Stock_Prices_with_Emotions.png)

* **æŸå¤±å›¾åˆ†æ**ï¼š

  ç”±Fig2å«æƒ…æ„Ÿçš„è‚¡ç¥¨ä»·æ ¼LSTMæŸå¤±å›¾å¯ä»¥çœ‹å‡ºï¼ŒMSEéšè¿­ä»£æ¬¡æ•°å¢åŠ è€Œå‡å°ï¼Œåœ¨å¤§çº¦30æ¬¡è¿­ä»£åï¼Œå…¶è¶‹äºç¨³å®šï¼ˆæ”¶æ•›ï¼‰ã€‚

#### 3.6.6 é¢„æµ‹ç»“æœå¹¶åå½’ä¸€åŒ–

```python
# å› ä¸ºåªè¦å¯¹ç»“æœåˆ—è¿›è¡Œåå½’ä¸€åŒ–æ“ä½œï¼Œ
# æ•…ä¸ç”¨inverse_transformå‡½æ•°ï¼Œ
# è¿™é‡Œè‡ªå®šä¹‰å¯¹æŸåˆ—çš„åå½’ä¸€åŒ–å‡½æ•° inverse_transform_col
def inverse_transform_col(_scaler, y, n_col):
    """
    å¯¹æŸä¸ªåˆ—è¿›è¡Œåå½’ä¸€åŒ–å¤„ç†çš„å‡½æ•°
    :param _scaler: sklearnå½’ä¸€åŒ–æ¨¡å‹
    :param y: éœ€è¦åå½’ä¸€åŒ–çš„æ•°æ®åˆ—
    :param n_col: yåœ¨å½’ä¸€åŒ–æ—¶æ‰€å±çš„åˆ—ç¼–å·
    :return: yçš„åå½’ä¸€åŒ–ç»“æœ
    """
    y = y.copy()
    y -= _scaler.min_[n_col]
    y /= _scaler.scale_[n_col]
    return y
```

```python
# æ¨¡å‹é¢„æµ‹ç»“æœç»˜å›¾å‡½æ•°
def predictGraph(yTrain, yPredict, yTest, timelabels, title, num):
    """
    é¢„æµ‹ç»“æœå›¾åƒç»˜åˆ¶å‡½æ•°
    :param yTrain: è®­ç»ƒé›†ç»“æœ
    :param yPredict: éªŒè¯é›†çš„é¢„æµ‹ç»“æœ
    :param yTest: éªŒè¯é›†çš„çœŸå®ç»“æœ
    :param timelabels: xè½´åˆ»åº¦æ ‡ç­¾
    :param title: å›¾è¡¨æ ‡é¢˜
    :param num: å›¾æ ‡ç¼–å·
    :return: æ— 
    """
    len_yTrain = yTrain.shape[0]
    len_y = len_yTrain+yPredict.shape[0]
    # çœŸå®æ›²çº¿ç»˜åˆ¶
    plt.plot(np.concatenate([yTrain,yTest]), color='r', label='sample')
    # é¢„æµ‹æ›²çº¿ç»˜åˆ¶
    plt.plot([x for x in range(len_yTrain,len_y)],yPredict, color='g', label='predict')
    # æ ‡é¢˜å’Œè½´æ ‡ç­¾
    plt.title('Fig'+num+'. '+title)
    plt.xlabel('date')
    plt.ylabel('close')
    plt.legend()
    # åˆ»åº¦å’Œåˆ»åº¦æ ‡ç­¾
    xticks = [0,len_yTrain,len_y-1]
    xtick_labels = [timelabels[x] for x in xticks]
    plt.xticks(ticks=xticks, labels=xtick_labels, rotation=30)
    # ä¿å­˜äº è¡¥å……æ•°æ®1925102007/
    savingPath = 'è¡¥å……æ•°æ®1925102007/fig'+num+'_'+title.replace(' ', '_')+'.png'
    plt.savefig(savingPath, dpi=400, bbox_inches='tight')
    # å±•ç¤º
    plt.show()
```

```python
# ç”±X_testå‰æ—¥è‚¡ç¥¨æŒ‡æ ‡é¢„æµ‹å½“å¤©è‚¡ç¥¨closeå€¼
# æ³¨ï¼špredictç”Ÿæˆçš„arrayéœ€é™ç»´æˆ shape=(n_samples, )
y_predict = model.predict(X_test)[:,0]

# åå½’ä¸€åŒ–
# é‡æ–°è¯»å– AAPLè‚¡ç¥¨ä»·æ ¼èåˆæƒ…æ„Ÿ.csv
sharePricesAAPLwithEmotion = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼èåˆæƒ…æ„Ÿ.csv')
col_n = sharePricesAAPLwithEmotion.shape[1]-2
# é¢„æµ‹ç»“æœåå½’ä¸€åŒ–
inv_yPredict = inverse_transform_col(scaler, y_predict, col_n)
# çœŸå®ç»“æœåå½’ä¸€åŒ–
inv_yTest = inverse_transform_col(scaler, y_test, col_n)
# è®­ç»ƒé›†ç»“æœåå½’ä¸€åŒ–ï¼ˆä»¥ç»˜åˆ¶å®Œæ•´å›¾åƒï¼‰
inv_yTrain = inverse_transform_col(scaler, y_train, col_n)
# ç»˜å›¾
predictGraph(inv_yTrain, inv_yPredict, inv_yTest, timelabels=sharePricesAAPLwithEmotion['date'].values, title='Prediction Graph of Stock Prices with Emotions', num='3')
```

![fig3_Prediction_Graph_of_Stock_Prices_with_Emotions](fig3_Prediction_Graph_of_Stock_Prices_with_Emotions.png)

#### 3.6.7 æ¨¡å‹è¯„ä¼°

**è¯¯å·®è¯„ä»·æ–¹æ³•**ï¼š`MSE`

```python
# sklearn.metrics.mean_squared_error(y_true, y_pred)
mse = mean_squared_error(inv_yTest, inv_yPredict)
print('å¸¦æœ‰æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸º ', mse)
```

    å¸¦æœ‰æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸º  160.42007

**åˆ†æ**ï¼š

è§‚å¯ŸFig3å¯çŸ¥ï¼Œç”¨å«æœ‰æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®è®­ç»ƒçš„LSTMæ¨¡å‹é¢„æµ‹ç»“æœï¼ˆç»¿è‰²æ›²çº¿ï¼‰å’ŒçœŸå®ç»“æœï¼ˆçº¢è‰²æ›²çº¿çš„åæ®µï¼‰æ€»ä½“å˜åŒ–è¶‹åŠ¿ä¸€è‡´ï¼Œå³çœŸå®å€¼ä¸‹é™æˆ–ä¸Šå‡æ—¶ï¼Œé¢„æµ‹å€¼è·Ÿç€ä¸‹é™æˆ–ä¸Šå‡ã€‚åœ¨æ¨¡å‹é¢„æµ‹çš„å¼€å§‹é˜¶æ®µï¼Œæ‹Ÿåˆæ•ˆæœè¾ƒå¥½ï¼Œä½†éšç€æ—¶é—´æ¨ç§»ï¼Œé¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„ç»“æœå·®è·æ„ˆå‘å¢å¤§ã€‚

### 3.7 å¯¹æ¯”å®éªŒï¼šé¢„æµ‹çº¯æŠ€æœ¯æŒ‡æ ‡çš„è‚¡ç¥¨æ•°æ®

ä½œä¸ºå¯¹æ¯”ï¼Œå¯¼å…¥`è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼.csv`ï¼Œå…·ä½“æ“ä½œå’Œä¸Šè¿°ä¸€è‡´ï¼Œå¯¹ä¸å«æƒ…æ„Ÿç‰¹å¾çš„çº¯æŠ€æœ¯æŒ‡æ ‡è‚¡ç¥¨æ•°æ®è¿›è¡Œé¢„æµ‹åˆ†æã€‚

*ï¼ˆæ“ä½œåŸºæœ¬ä¸€è‡´ï¼Œæ•…ä¸ä½œè¯¦ç»†æ³¨é‡Šï¼‰*

#### 3.7.1 å¯¹æ¯”å®éªŒæµç¨‹ï¼ˆé€šç”¨å‡½æ•°æ„é€ ï¼‰

```python
def formatData(sharePricesData):
    """
    æ¨¡å¼åŒ–æ ·æœ¬æ•°æ®çš„å‡½æ•°
    :param sharePricesData: æ ·æœ¬æ•°æ®çš„DataFrame
    :return: X_train, X_test, y_train, y_test, scaler
    """
    # å½’ä¸€åŒ–
    _scaler = MinMaxScaler()
    _scaler = _scaler.fit(sharePricesData)
    sharePricesData = _scaler.fit_transform(sharePricesData)
    # æ„å»ºæœ‰ç›‘ç£æ•°æ®é›†
    sharePricesData = series_to_supervised(sharePricesData)
    # dtypeä¸ºfloat32
    sharePricesData = sharePricesData.values.astype(np.float32)
    # è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„åˆ’åˆ†
    _X_train, _X_test, _y_train, _y_test = train_test_split(sharePricesData[:,:-1], sharePricesData[:,-1], test_size=0.3, shuffle=False)
    # reshape input
    _X_train = _X_train.reshape((_X_train.shape[0], 1, _X_train.shape[1]))
    _X_test = _X_test.reshape((_X_test.shape[0], 1, _X_test.shape[1]))
    return _X_train, _X_test, _y_train, _y_test, _scaler
```

```python
def invTransformMulti(_scaler, _y_predict, _y_test, _y_train, _col_n):
    # æ‰¹é‡åå½’ä¸€åŒ–
    _inv_yPredict = inverse_transform_col(_scaler, _y_predict, _col_n)
    _inv_yTest = inverse_transform_col(_scaler, _y_test, _col_n)
    _inv_yTrain = inverse_transform_col(_scaler, _y_train, _col_n)
    return _inv_yPredict, _inv_yTest, _inv_yTrain
```

```python
# è¯»å–æ•°æ®
sharePricesAAPL = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼.csv', parse_dates=['date'], index_col='date').values
# æ ‡å‡†åŒ–æ•°æ®è¾“å…¥
X_train, X_test, y_train, y_test, scaler = formatData(sharePricesAAPL)
# å»ºæ¨¡
history, model = LSTMModelGenerate(X_train, X_test, y_train, y_test)
```

```python
# æŸå¤±å‡½æ•°ç»˜å›¾
drawLossGraph(history, title='LSTM Loss Graph for Stock Prices without Emotions', num='4')
```

![fig4_LSTM_Loss_Graph_for_Stock_Prices_without_Emotions](fig4_LSTM_Loss_Graph_for_Stock_Prices_without_Emotions.png)

```python
# é¢„æµ‹
y_predict = model.predict(X_test)[:,0]
# åå½’ä¸€åŒ–
sharePricesAAPL = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼.csv')
col_n = sharePricesAAPL.shape[1]-2
inv_yPredict, inv_yTest, inv_yTrain = invTransformMulti(scaler, y_predict, y_test, y_train, col_n)
# ç»˜å›¾
predictGraph(inv_yTrain, inv_yPredict, inv_yTest, timelabels=sharePricesAAPL['date'].values, title='Prediction Graph of Stock Prices without Emotions', num='5')
```

![fig5_Prediction_Graph_of_Stock_Prices_without_Emotions](fig5_Prediction_Graph_of_Stock_Prices_without_Emotions.png)

```python
# å‡æ–¹è¯¯å·®
mse = mean_squared_error(inv_yTest, inv_yPredict)
print('æ— æƒ…æ„Ÿç‰¹å¾çš„çº¯æŠ€æœ¯æŒ‡æ ‡è‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸º ', mse)
```

    æ— æƒ…æ„Ÿç‰¹å¾çš„çº¯æŠ€æœ¯æŒ‡æ ‡è‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸º  142.50227

#### 3.7.2 å¯¹æ¯”å®éªŒç»“æœåˆ†æ

å¯¹æ¯”Fig3å’ŒFig5ï¼ˆå«æƒ…æ„Ÿå’Œä¸å«æƒ…æ„Ÿï¼‰

* **å‡æ–¹è¯¯å·®**ï¼šé€šè¿‡å»é™¤æƒ…æ„Ÿä¿¡æ¯ï¼Œç”¨LSTMæ¨¡å‹å¾—å‡ºçš„çº¯æŠ€æœ¯æŒ‡æ ‡çš„è‚¡ç¥¨closeé¢„æµ‹ç»“æœå•å°±è¯¯å·®æ¥çœ‹è¦ä¼˜äºå«æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœï¼Œ**çº¯æŠ€æœ¯æŒ‡æ ‡é¢„æµ‹çš„ç²¾åº¦æ›´é«˜ï¼Œæ€»ä½“ä¸Šæ›´æ¥è¿‘äºçœŸå€¼**ã€‚

  > MSE (å«æƒ…æ„Ÿç‰¹å¾) = `160.42007`
  >
  > MSE (çº¯æŠ€æœ¯æŒ‡æ ‡) = `142.50227`

* **æ›²çº¿ç‰¹å¾**ï¼šæ˜¾ç„¶ï¼Œ**å«æœ‰æƒ…æ„Ÿæ•°æ®ä¿¡æ¯çš„é¢„æµ‹ç»“æœæ›²çº¿è¾ƒæ— æƒ…æ„Ÿçš„é¢„æµ‹æ›²çº¿æ›´çµæ•**ã€‚Fig3ï¼ˆå«æƒ…æ„Ÿç‰¹å¾ï¼‰çš„é¢„æµ‹æ›²çº¿éšçœŸå€¼æ›²çº¿çš„å‡é™è€Œæ¶¨è·Œï¼ŒçœŸå€¼æ›²çº¿çš„å˜åŒ–ï¼ˆçªå˜ï¼‰è¶‹åŠ¿è¾ƒä¸ºå®Œæ•´åœ°ä½“ç°åœ¨é¢„æµ‹æ›²çº¿ä¸­ï¼Œè€ŒFig5ï¼ˆçº¯æŠ€æœ¯æŒ‡æ ‡ï¼‰çš„é¢„æµ‹æ›²çº¿éšçœŸå€¼æ›²çº¿çš„æ³¢åŠ¨å¹¶ä¸æ˜æ˜¾ã€‚

  > Fig3. Prediction Graph of Stock Prices with Emotions
  >
  > Fig5. Prediction Graph of Stock Prices without Emotions

#### 3.7.3 å¯¹æ¯”å®éªŒç»“è®º

åœ¨ç°æœ‰æ•°æ®ä¸‹ï¼Œä»æ€»ä½“ä¸Šæ¥çœ‹ï¼Œçº¯æŠ€æœ¯æŒ‡æ ‡çš„è‚¡ç¥¨æ•°æ®é¢„æµ‹ç²¾åº¦æ›´é«˜ï¼Œä½†ä»å±€éƒ¨æ¥çœ‹ï¼Œèå…¥äº†æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®åˆ™æ›´åŠ çµæ•ã€‚å®éªŒç»“æœåŸºæœ¬å’Œé¢„æœŸä¸€è‡´ã€‚

ç»“æœè¡¨æ˜ï¼Œè‚¡ç¥¨çš„ä»·æ ¼æ¶¨è·Œå¹¶éæ— è§„å¾‹çš„éšæœºæ¸¸èµ°ï¼Œè€Œæ˜¯å’Œè‚¡æ°‘çš„æƒ…æ„Ÿæ¯æ¯ç›¸å…³ã€‚åœ¨å¯¹è‚¡ç¥¨æ•°æ®çš„é¢„æµ‹ä¸­ï¼Œèå…¥äº’è”ç½‘è®ºå›ä¸Šè‚¡æ°‘å¤§ä¼—çš„æƒ…æ„Ÿæ•°æ®ä¿¡æ¯ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åˆ¤æ–­å‡ºæœªæ¥ä¸€æ®µæ—¶é—´å†…è‚¡ç¥¨çš„æ¶¨è·Œæƒ…å†µï¼Œä»è€Œå¸®åŠ©åˆ¤æ–­è‚¡ç¥¨çš„æœ€ä½³è´­å…¥ç‚¹å’Œå–å‡ºç‚¹ã€åˆ†æè‚¡ç¥¨æŠ•èµ„é£é™©ã€‚æƒ…æ„Ÿæ•°æ®ä¿¡æ¯æœ‰åŠ©äºåœ¨é‡åŒ–æŠ•èµ„ä¸­è¾…åŠ©è‚¡æ°‘å’Œæ•°æ®åˆ†æå¸ˆåšå‡ºæœ€ä¼˜å†³ç­–ã€‚

### 3.8 è¡¥å……å¯¹æ¯”å®éªŒï¼šè¡¥å……AAPLè‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡æ ·æœ¬é‡è¿›è¡Œé¢„æµ‹

åœ¨ <a id="mark2" href="#mark1">`æ•°æ®è”åˆ`</a> æ­¥éª¤æ—¶ï¼Œå‘ç°æ‰€ç»™`è¡¥å……æ•°æ®1925102007/AAPLè‚¡ç¥¨ä»·æ ¼.csv`æ•°æ®å¹¶ä¸èƒ½è¦†ç›–æ‰€æœ‰çš„è¯„è®ºæ•°æ®ï¼ˆ`allPosAndNeg.csv`ï¼‰ã€‚

æ­¤å¤–ï¼Œè¯¥æ•°æ®æ ·æœ¬é‡è¾ƒå°‘ï¼ŒæŒ‰è®­ç»ƒé›†å’ŒéªŒè¯é›†7:3æ¯”ä¾‹åˆ’åˆ†åï¼Œå¯¼è‡´è®­ç»ƒé›†æ ·æœ¬æ•°åªæœ‰88æ¡ã€‚

å› æ­¤å†³å®šä½¿ç”¨è‹±ä¸ºè´¢æƒ…è‚¡ç¥¨è¡Œæƒ…ç½‘ç«™æ‰€æä¾›çš„2018å¹´å…¨å¹´AAPLè‚¡ç¥¨å·¥ä½œæ—¥çº¯æŠ€æœ¯æŒ‡æ ‡æ•°æ®ï¼Œä½¿ç”¨ä¸Šè¿°æ–¹æ³•å¯¹æ”¶ç›˜ä»·ï¼ˆcloseï¼‰è¿›è¡Œé¢„æµ‹ï¼Œå’Œ`2.5 å¯¹æ¯”å®éªŒ`è¿›è¡Œå¯¹æ¯”ã€‚

> äº‹å®ä¸Šï¼Œ
>
> `AAPLè‚¡ç¥¨ä»·æ ¼.csv`è¦†ç›–æ—¶é—´ä¸º2018-07-02è‡³2018-12-31ï¼Œ
>
> `allPosAndNeg.csv`è¦†ç›–æ—¶é—´ä¸º2018-01-05è‡³2018-12-31.

#### 3.8.1 æ•°æ®è·å–

ä»[è‹±ä¸ºè´¢æƒ…AAPLä¸ªè‚¡é¡µé¢](https://cn.investing.com/equities/apple-computer-inc-historical-data)ä¸‹è½½è¿‘äº”å¹´AAPLçº¯æŠ€æœ¯æŒ‡æ ‡è‚¡ç¥¨æ•°æ®ï¼Œå‚¨å­˜äº`è¡¥å……æ•°æ®1925102007\AAPLHistoricalData_5years.csv`. 

#### 3.8.2 æ•°æ®å¤„ç†

```python
# è¯»å–æ•°æ®
allYearAAPL = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPLHistoricalData_5years.csv', parse_dates=['Date'], index_col='Date')
# æ—¶é—´åºåˆ—ç´¢å¼•åˆ‡ç‰‡
allYearAAPL = allYearAAPL['2018-12-31':'2018-01-01']
# æ’åº
allYearAAPL.sort_index(inplace=True)
# å±•ç¤º
allYearAAPL
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Close/Last</th>
      <th>Volume</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-01-02</th>
      <td>$43.065</td>
      <td>101602160</td>
      <td>$42.54</td>
      <td>$43.075</td>
      <td>$42.315</td>
    </tr>
    <tr>
      <th>2018-01-03</th>
      <td>$43.0575</td>
      <td>117844160</td>
      <td>$43.1325</td>
      <td>$43.6375</td>
      <td>$42.99</td>
    </tr>
    <tr>
      <th>2018-01-04</th>
      <td>$43.2575</td>
      <td>89370600</td>
      <td>$43.135</td>
      <td>$43.3675</td>
      <td>$43.02</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-12-27</th>
      <td>$39.0375</td>
      <td>206435400</td>
      <td>$38.96</td>
      <td>$39.1925</td>
      <td>$37.5175</td>
    </tr>
    <tr>
      <th>2018-12-28</th>
      <td>$39.0575</td>
      <td>166962400</td>
      <td>$39.375</td>
      <td>$39.63</td>
      <td>$38.6375</td>
    </tr>
    <tr>
      <th>2018-12-31</th>
      <td>$39.435</td>
      <td>137997560</td>
      <td>$39.6325</td>
      <td>$39.84</td>
      <td>$39.12</td>
    </tr>
  </tbody>
</table>
<p>251 rows Ã— 5 columns</p>
</div>

```python
# pandaså­—ç¬¦ä¸²åˆ‡å‰²ã€Seriesç±»å‹ä¿®æ”¹ï¼ˆå»é™¤$ï¼‰
allYearAAPL[['Close/Last', 'Open', 'High', 'Low']] = allYearAAPL[['Close/Last', 'Open', 'High', 'Low']].apply(lambda x: (x.str[1:]).astype(np.float32))
# reindex
allAAPL_newColOrder = ['Open', 'High', 'Low', 'Volume', 'Close/Last']
allYearAAPL = allYearAAPL.reindex(columns=allAAPL_newColOrder)
# ä¿å­˜ä¸ºAAPL2018allYearData.csv
allYearAAPL.to_csv('è¡¥å……æ•°æ®1925102007/AAPL2018allYearData.csv')
# å±•ç¤º
allYearAAPL
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Volume</th>
      <th>Close/Last</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-01-02</th>
      <td>42.540001</td>
      <td>43.075001</td>
      <td>42.314999</td>
      <td>101602160</td>
      <td>43.064999</td>
    </tr>
    <tr>
      <th>2018-01-03</th>
      <td>43.132500</td>
      <td>43.637501</td>
      <td>42.990002</td>
      <td>117844160</td>
      <td>43.057499</td>
    </tr>
    <tr>
      <th>2018-01-04</th>
      <td>43.134998</td>
      <td>43.367500</td>
      <td>43.020000</td>
      <td>89370600</td>
      <td>43.257500</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-12-27</th>
      <td>38.959999</td>
      <td>39.192501</td>
      <td>37.517502</td>
      <td>206435400</td>
      <td>39.037498</td>
    </tr>
    <tr>
      <th>2018-12-28</th>
      <td>39.375000</td>
      <td>39.630001</td>
      <td>38.637501</td>
      <td>166962400</td>
      <td>39.057499</td>
    </tr>
    <tr>
      <th>2018-12-31</th>
      <td>39.632500</td>
      <td>39.840000</td>
      <td>39.119999</td>
      <td>137997560</td>
      <td>39.435001</td>
    </tr>
  </tbody>
</table>
<p>251 rows Ã— 5 columns</p>
</div>

#### 3.8.3 é¢„æµ‹åˆ†æ

```python
# æ ‡å‡†åŒ–æ•°æ®è¾“å…¥
X_train, X_test, y_train, y_test, scaler = formatData(allYearAAPL)
# å»ºæ¨¡
history, model = LSTMModelGenerate(X_train, X_test, y_train, y_test)
# æŸå¤±å‡½æ•°ç»˜å›¾
drawLossGraph(history, title='LSTM Loss Graph for 2018 All Year AAPL Stock Prices', num='6')
```

![fig6_LSTM_Loss_Graph_for_2018_All_Year_AAPL_Stock_Prices](fig6_LSTM_Loss_Graph_for_2018_All_Year_AAPL_Stock_Prices.png)

```python
# é¢„æµ‹
y_predict = model.predict(X_test)[:,0]
# åå½’ä¸€åŒ–
allYearAAPL = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPL2018allYearData.csv')
col_n = allYearAAPL.shape[1]-2
inv_yPredict, inv_yTest, inv_yTrain = invTransformMulti(scaler, y_predict, y_test, y_train, col_n)
# ç»˜å›¾
predictGraph(inv_yTrain, inv_yPredict, inv_yTest, timelabels=allYearAAPL['Date'].values, title='Prediction Graph of 2018 All Year AAPL Stock Prices', num='7')
```

![fig7_Prediction_Graph_of_2018_All_Year_AAPL_Stock_Prices](fig7_Prediction_Graph_of_2018_All_Year_AAPL_Stock_Prices.png)

```python
# å‡æ–¹è¯¯å·®
mse = mean_squared_error(inv_yTest, inv_yPredict)
print('2018å…¨å¹´çº¯æŠ€æœ¯æŒ‡æ ‡AAPLè‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸º ', mse)
```

#### 3.8.4 ç»“æœåˆ†æ

ç”±`Fig7. Prediction Graph of 2018 All Year AAPL Stock Prices`ã€`2018å…¨å¹´çº¯æŠ€æœ¯æŒ‡æ ‡AAPLè‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®`å’Œ`2.5 ä¸å«æƒ…æ„Ÿç‰¹å¾çš„AAPLè‚¡ç¥¨æ•°æ®é¢„æµ‹çš„å¯¹æ¯”å®éªŒ`æ¯”è¾ƒå¾—çŸ¥ï¼Œ**åœ¨å¢åŠ è‚¡ç¥¨çš„æ—¶é—´åºåˆ—æ•°æ®å**ï¼Œå³ç”±åŸæœ¬`2018-07-02ï½2018-12-31`æ‰©å……è‡³`2018-01-01~2018-12-31`ï¼Œ**çº¯æŠ€æœ¯æŒ‡æ ‡é¢„æµ‹çš„ç²¾åº¦å¤§å¹…æå‡ï¼ŒLSTMæ¨¡å‹çš„æ‹Ÿåˆæ•ˆæœæä½³**ã€‚

**ç”±æ­¤æ¨æ–­**ï¼Œ`Fig3. `å’Œ`Fig5. `ï¼ˆå³æœªå¢æ·»æ•°æ®å‰çš„AAPLå«æƒ…æ„Ÿç‰¹å¾é¢„æµ‹å›¾å’Œçº¯æŠ€æœ¯æŒ‡æ ‡é¢„æµ‹å›¾ï¼‰çš„é¢„æµ‹ç»“æœç²¾åº¦ä½ï¼Œä¸”éšæ—¶é—´æ¨ç§»ï¼Œ**é¢„æµ‹ç»“æœä¸¥é‡åç¦»çœŸå€¼çš„åŸå› åœ¨äºæ ·æœ¬æ•°ç›®ä¸è¶³ï¼Œå¯¼è‡´LSTMæ¨¡å‹è®­ç»ƒä¸åˆ°ä½**ã€‚æ¥ä¸‹æ¥ï¼Œå°†æ·»åŠ è¡¥å……æ•°æ®åçš„2018å…¨å¹´AAPLè‚¡ç¥¨æ•°æ®èåˆæƒ…æ„Ÿç‰¹å¾ï¼Œè¿›è¡Œå«æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®é¢„æµ‹ï¼Œä»¥éªŒè¯è¿™ä¸€æ¨æ–­ã€‚

### 3.9 2018å…¨å¹´å«æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®é¢„æµ‹å®éªŒ

#### 3.9.1 æƒ…æ„Ÿç‰¹å¾æ•°æ®èšåˆ

```python
# æ–‡ä»¶è¯»å–
allYearAAPL_withEmos = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPL2018allYearData.csv')
allPosAndNeg = pd.read_csv('è¡¥å……æ•°æ®1925102007/allPosAndNeg.csv')
# åˆå¹¶
allYearAAPL_withEmos = allYearAAPL_withEmos.merge(allPosAndNeg, how='inner', left_on='Date', right_on='date').drop('date', axis=1)
# åºåˆ—åŒ–æ—¶é—´ç´¢å¼•date
allYearAAPL_withEmos['Date'] = pd.DatetimeIndex(allYearAAPL_withEmos['Date'])
allYearAAPL_withEmos.set_index('Date', inplace=True)
# reindex
allYearAAPLwithEmos_newColOrder = ['Open',
                                   'High',
                                   'Low',
                                   'Volume',
                                   'pos',
                                   'neg',
                                   'Close/Last']
allYearAAPL_withEmos = allYearAAPL_withEmos.reindex(columns=allYearAAPLwithEmos_newColOrder)
# ä¿å­˜
allYearAAPL_withEmos.to_csv('è¡¥å……æ•°æ®1925102007/AAPL2018allYearData_withEmos.csv')
# å±•ç¤º
allYearAAPL_withEmos
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Volume</th>
      <th>pos</th>
      <th>neg</th>
      <th>Close/Last</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2018-01-05</th>
      <td>43.3600</td>
      <td>43.8425</td>
      <td>43.2625</td>
      <td>94359720</td>
      <td>0.041667</td>
      <td>0.043478</td>
      <td>43.7500</td>
    </tr>
    <tr>
      <th>2018-01-08</th>
      <td>43.5875</td>
      <td>43.9025</td>
      <td>43.4825</td>
      <td>82095480</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>43.5875</td>
    </tr>
    <tr>
      <th>2018-01-09</th>
      <td>43.6375</td>
      <td>43.7650</td>
      <td>43.3525</td>
      <td>86128800</td>
      <td>0.000000</td>
      <td>0.090909</td>
      <td>43.5825</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2018-12-21</th>
      <td>39.2150</td>
      <td>39.5400</td>
      <td>37.4075</td>
      <td>381991600</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>37.6825</td>
    </tr>
    <tr>
      <th>2018-12-24</th>
      <td>37.0375</td>
      <td>37.8875</td>
      <td>36.6475</td>
      <td>148676920</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>36.7075</td>
    </tr>
    <tr>
      <th>2018-12-26</th>
      <td>37.0750</td>
      <td>39.3075</td>
      <td>36.6800</td>
      <td>232535400</td>
      <td>0.090909</td>
      <td>0.090909</td>
      <td>39.2925</td>
    </tr>
  </tbody>
</table>
<p>245 rows Ã— 7 columns</p>
</div>

#### 3.9.2 é¢„æµ‹åˆ†æ

```python
# æ ‡å‡†åŒ–æ•°æ®è¾“å…¥
X_train, X_test, y_train, y_test, scaler = formatData(allYearAAPL_withEmos)
# å»ºæ¨¡
history, model = LSTMModelGenerate(X_train, X_test, y_train, y_test)
# æŸå¤±å‡½æ•°ç»˜å›¾
drawLossGraph(history, title='LSTM Loss Graph for 2018 All Year AAPL Stock Prices with Emotions', num='8')
```

![fig8_LSTM_Loss_Graph_for_2018_All_Year_AAPL_Stock_Prices_with_Emotions](fig8_LSTM_Loss_Graph_for_2018_All_Year_AAPL_Stock_Prices_with_Emotions.png)

```python
# é¢„æµ‹
y_predict = model.predict(X_test)[:,0]
# åå½’ä¸€åŒ–
allYearAAPL_withEmos = pd.read_csv('è¡¥å……æ•°æ®1925102007/AAPL2018allYearData_withEmos.csv')
col_n = allYearAAPL_withEmos.shape[1]-2
inv_yPredict, inv_yTest, inv_yTrain = invTransformMulti(scaler, y_predict, y_test, y_train, col_n)
# ç»˜å›¾
predictGraph(inv_yTrain, inv_yPredict, inv_yTest, timelabels=allYearAAPL_withEmos['Date'].values, title='Prediction Graph of 2018 All Year AAPL Stock Prices with Emotions', num='9')
```

![fig9_Prediction_Graph_of_2018_All_Year_AAPL_Stock_Prices_with_Emotions](fig9_Prediction_Graph_of_2018_All_Year_AAPL_Stock_Prices_with_Emotions.png)

```python
# å‡æ–¹è¯¯å·®
mse = mean_squared_error(inv_yTest, inv_yPredict)
print('2018å…¨å¹´å«æƒ…æ„Ÿç‰¹å¾çš„AAPLè‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸º ', mse)
```

    2018å…¨å¹´å«æƒ…æ„Ÿç‰¹å¾çš„AAPLè‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœçš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä¸º  1.5526791

#### 3.9.3 ç»“æœåˆ†æ

**æ¨¡å‹è®­ç»ƒæŸå¤±å›¾**ï¼šå¯¹æ¯”`Fig2. LSTM Loss Graph for Stock Prices with Emotions`å’Œ`Fig8. LSTM Loss Graph for 2018 All Year AAPL Stock Prices with Emotions`ï¼Œå‘ç°ä½¿ç”¨2018å…¨å¹´AAPLå«æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®è®­ç»ƒLSTMæ¨¡å‹ï¼Œåœ¨çº¦10æ¬¡å·¦å³epochsæ—¶æ”¶æ•›ï¼Œè€Œéƒ¨åˆ†AAPLå«æƒ…æ„Ÿç‰¹å¾çš„è‚¡ç¥¨æ•°æ®è®­ç»ƒåˆ™éœ€è¦çº¦20æ¬¡å·¦å³epochsæ‰èƒ½æ”¶æ•›ã€‚**è¡¨æ˜ï¼Œéšè®­ç»ƒæ ·æœ¬çš„å¢åŠ ï¼ŒLSTMæ¨¡å‹ä½¿æŸå¤±å‡½æ•°æ”¶æ•›æ‰€éœ€çš„è¿­ä»£æ¬¡æ•°æ›´å°‘ï¼Œä¸”æ‹Ÿåˆæ•ˆæœæ›´ä½³**ã€‚

**é¢„æµ‹ç»“æœå›¾**ï¼šå¯¹æ¯”`Fig7. Prediction Graph of 2018 All Year AAPL Stock Prices`å’Œ`Fig9. Prediction Graph of 2018 All Year AAPL Stock Prices with Emotions`ï¼ˆå³åªå«çº¯æŠ€æœ¯æŒ‡æ ‡çš„å’ŒåŠ å…¥æƒ…æ„Ÿç‰¹å¾åçš„2018å…¨å¹´AAPLè‚¡ç¥¨æ•°æ®é¢„æµ‹ç»“æœå›¾ï¼‰ï¼Œå‘ç°äºŒè€…å·®å¼‚ç”šå¾®ã€‚ä½†é€šè¿‡äºŒè€…MSEå€¼ä¸éš¾å‘ç°ï¼Œ**MSE (2018å…¨å¹´å«æƒ…æ„Ÿç‰¹å¾çš„AAPLè‚¡ç¥¨æ•°æ®) < MSE (2018å…¨å¹´çº¯æŠ€æœ¯æŒ‡æ ‡AAPLè‚¡ç¥¨æ•°æ®)ï¼Œè¡¨æ˜åœ¨æ€»ä½“æ ·æœ¬é‡æ‰©å¤§ï¼Œè®©è¯„è®ºæƒ…æ„Ÿç‰¹å¾æ•°æ®çš„æ—¶é—´èƒ½å¤Ÿè¦†ç›–æ‰€æœ‰è‚¡ç¥¨æŠ€æœ¯æŒ‡æ ‡çš„æƒ…å†µä¸‹ï¼Œå‘çº¯æŠ€æœ¯æŒ‡æ ‡çš„è‚¡ç¥¨æ•°æ®ä¸­æ·»åŠ æƒ…æ„Ÿç‰¹å¾æ•°æ®åï¼Œèƒ½å¤Ÿå¢åŠ å¯¹è‚¡ç¥¨æ”¶ç›˜ä»·closeçš„é¢„æµ‹ç²¾åº¦**ã€‚

> MSE (2018å…¨å¹´å«æƒ…æ„Ÿç‰¹å¾çš„AAPLè‚¡ç¥¨æ•°æ®) = 1.5526791
>
> MSE (2018å…¨å¹´çº¯æŠ€æœ¯æŒ‡æ ‡AAPLè‚¡ç¥¨æ•°æ®) = 1.7402486

## 4. ç»“è®ºä¸æ€»ç»“

æœ¬å®éªŒæ¢ç©¶äº†æƒ…æ„Ÿç»“æ„åŒ–ç‰¹å¾æ•°æ®åœ¨LSTMè‚¡ç¥¨é¢„æµ‹æ¨¡å‹ä¸­çš„å½±å“ã€‚åˆ©ç”¨Pandaså¯¹æ‰€ç»™æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼ˆæ•°æ®è½½å…¥ã€æ¸…æ´—ä¸å‡†å¤‡ã€è§„æ•´ã€æ—¶é—´åºåˆ—å¤„ç†ã€æ•°æ®èšåˆç­‰ï¼‰ï¼Œç¡®ä¿æ•°æ®çš„å¯ç”¨æ€§ã€‚å†å€ŸåŠ©NLTKå’ŒLMé‡‘èè¯åº“ï¼Œå¯¹éç»“æ„åŒ–æ–‡æœ¬ä¿¡æ¯è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œå¹¶å°†æ‰€å¾—ç»“æ„åŒ–æ•°æ®èå…¥çº¯æŠ€æœ¯æŒ‡æ ‡çš„è‚¡ç¥¨æ•°æ®ä¸­ã€‚åˆ†æå„è‚¡ç¥¨æŒ‡æ ‡çš„ç›¸å…³æ€§ï¼Œå®ç°æ•°æ®é™ç»´ï¼Œæå‡æ¨¡å‹è®­ç»ƒé€Ÿåº¦ã€‚åŸºäºKerasçš„ä»¥MSEä¸ºè¯¯å·®è¯„ä»·æ–¹æ³•çš„LSTMæ¨¡å‹ï¼Œåˆ†åˆ«ä½¿ç”¨å«æœ‰æƒ…æ„Ÿå’Œä¸å«æƒ…æ„Ÿçš„éƒ¨åˆ†è‚¡ç¥¨æ•°æ®å’Œ2018å…¨å¹´è‚¡ç¥¨æ•°æ®å®ç°å¯¹è‚¡ç¥¨æ”¶ç›˜ä»·Closeçš„é¢„æµ‹ã€‚

å®éªŒç»“æœè¡¨æ˜ï¼ŒLSTMæ¨¡å‹é¢„æµ‹è‚¡ç¥¨æ”¶ç›˜ä»·Closeæ—¶ï¼Œåœ¨è®­ç»ƒæ ·æœ¬é‡è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œæ— è®ºæœ‰æ— æƒ…æ„Ÿæ•°æ®çš„èå…¥ï¼Œé¢„æµ‹å€¼éšæ—¶é—´çš„æ¨ç§»ä¸¥é‡åç¦»çœŸå€¼ï¼Œå³é¢„æµ‹ç²¾åº¦è¾ƒä½ï¼Œè€Œæƒ…æ„Ÿæ•°æ®çš„èå…¥è®©é¢„æµ‹å€¼å˜å¾—æ›´åŠ çµæ•ï¼Œæ¶¨è·Œæƒ…å†µæ›´ç¬¦åˆçœŸå€¼ï¼Œä½†é¢„æµ‹ç²¾åº¦æœ‰æ‰€ä¸‹é™ã€‚ç„¶è€Œï¼Œå½“è®­ç»ƒæ ·æœ¬å……è¶³æ—¶ï¼Œä¸ä»…é¢„æµ‹ç²¾åº¦å¤§å¹…æå‡ï¼Œè€Œä¸”å› èå…¥äº†æƒ…æ„Ÿç‰¹å¾æ•°æ®ï¼Œä½¿å¾—é¢„æµ‹çµæ•åº¦é€‚å½“å¢åŠ ï¼Œå¯¼è‡´æ€»ä½“é¢„æµ‹ç²¾åº¦å†æ¬¡å¢é•¿ã€‚

## 5. å‚è€ƒæ–‡çŒ®

<a id="ref1" href="#toref1">[1]</a> Wes McKinney. åˆ©ç”¨Pythonè¿›è¡Œæ•°æ®åˆ†æ[M]. æœºæ¢°å·¥ä¸šå‡ºç‰ˆç¤¾. 2013

<a id="ref2" href="#toref2">[2]</a> æ´ªå¿—ä»¤, å´æ¢…çº¢. è‚¡ç¥¨å¤§æ•°æ®æŒ–æ˜å®æˆ˜â€”â€”è‚¡ç¥¨åˆ†æç¯‡[M]. æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾. 2020

<a id="ref3" href="#toref3">[3]</a> æ¨å¦¥, æä¸‡é¾™, éƒ‘å±±çº¢. èåˆæƒ…æ„Ÿåˆ†æä¸SVM_LSTMæ¨¡å‹çš„è‚¡ç¥¨æŒ‡æ•°é¢„æµ‹. è½¯ä»¶å¯¼åˆŠ, 2020(8):14-18.

<a id="ref4" href="#toref4">[4]</a> Francesca Lazzeri. Machine Learning for Time Series Forecasting with Python[M]. Wiley. 2020


---
> æ•°æ®é›†ä¸‹è½½ï¼š
>
> ç™¾åº¦äº‘- https://pan.baidu.com/s/1tC1AFx0kMHPUGobvqf47pg
>
> åå¤§äº‘ç›˜- https://pan.hqu.edu.cn/share/a474d56c6b6557f7a7fd0e0eb7
>
> å¯†ç - ued8